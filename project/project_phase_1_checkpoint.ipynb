{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Phase 1\n",
    "\n",
    "For this phase I was planning on having the algorithm in the paper implemented and tested. I was not able to make it to this point though. I was able to get some training and test data from the paper. Their was one dataset that the only place I found to download it has a restriction of not being able to be used for student projects. \n",
    "\n",
    "I was able to implement the Histogram Of Oriented Gradients (HOG) feature extraction. I did it how the paper said to do hopefully I implemented it correctly.\n",
    "I first took the square root of each pixel value in the image. Then I calculated the Gradient of x and y. I did this by using two nested loops to go through each pixel and calculate the central differences. I then calculated the magnitude and angle of the gradient. \n",
    "I then divided the image into 8x8 cells and looped through these cells and added up the gradient magnitude contributions based on ther orientation.\n",
    "I then normalized the blocks by dividing it by the square root of the sum of squares of its valus\n",
    "Then I flattened it into a 1d array and used that as the feature vector.\n",
    "\n",
    "\n",
    "I was also able to some preprocessing of the images and get them into the right image sizes. For that one I used opencv's CascadeClassifier to detect the faces which the basic one worked sometimes but to get more faces cropped properly I used YOLO3 to test if it cropped an actual face. I was having issues where it would crop the wrong part of the image. I used YOLO3 to test this and if it didn't detect a face it would use a different classifier xml setting to detect the face. I got allot better performance with this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets used\n",
    "* https://www.kaggle.com/datasets/tapakah68/facial-emotion-recognition\n",
    "*https://www.kaggle.com/datasets/davilsena/ckdataset\n",
    "\n",
    "\n",
    "\n",
    "### Unable to use Dataset\n",
    "Not able to use the JAFFE dataset due to restrictions on the dataset. Including the restriction of not being able to be used for homework, undergraduate projects and course projects. Unless there is another way to access it but I wasn't able to find any other way to access it.\n",
    "https://zenodo.org/records/3451524\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CK+ Dataset\n",
    "\n",
    "0: anger\n",
    "1: disgust\n",
    "2: fear\n",
    "3: happy\n",
    "4: sad\n",
    "5: surprise\n",
    "6: neutral\n",
    "7: contempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emotion                                             pixels     Usage\n",
      "0        6  36 39 35 25 19 11 8 7 3 13 15 9 21 57 75 90 10...  Training\n",
      "1        6  88 74 19 4 5 5 3 12 8 21 15 21 15 18 24 29 32 ...  Training\n",
      "2        6  9 2 4 7 1 1 1 0 7 29 49 76 115 141 156 169 177...  Training\n",
      "3        6  104 106 108 104 95 50 60 61 58 83 126 133 139 ...  Training\n",
      "4        6  68 72 67 67 6 2 1 1 1 1 1 14 24 24 38 65 79 94...  Training\n",
      "test\n",
      "6\n",
      "img shape:  2304\n",
      "size: 48 x 48\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img is gray scale:  True\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/davilsena/ckdataset\n",
    "\n",
    "# load in datasets\n",
    "# load in the ckextneded.csv file\n",
    "ckplus_dataset = pd.read_csv(cwd + '/datasets/ckextended.csv')\n",
    "print(ckplus_dataset.head())\n",
    "print(\"test\")\n",
    "print(ckplus_dataset.iloc[0, 0])\n",
    "\n",
    "# display the first image in the dataset by getting the data in the first row of the second column\n",
    "# and reshaping it to 48x48\n",
    "img = ckplus_dataset.iloc[0, 1]\n",
    "img = img.split(' ')\n",
    "img = np.array(img, dtype='float32')\n",
    "print(\"img shape: \", img.shape[0])\n",
    "size = int(np.sqrt(img.shape[0]))\n",
    "print(f\"size: {size} x {size}\")\n",
    "img = img.reshape((size, size))\n",
    "# upscale image to 64x64\n",
    "img = cv2.resize(img, (64, 64))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# check if img is grey scale\n",
    "print(\"img is gray scale: \", img.ndim == 2)\n",
    "\n",
    "# if ckplus_dataset row in the 3rd column is training, then the image is for training, else it is for testing\n",
    "# create a list of training and testing images\n",
    "ckplus_images = []\n",
    "ckplus_labels = []\n",
    "\n",
    "for i in range(0, ckplus_dataset.shape[0]):\n",
    "    img = ckplus_dataset.iloc[i, 1]\n",
    "    img = img.split(' ')\n",
    "    img = np.array(img, dtype='float32')\n",
    "    size = int(np.sqrt(img.shape[0]))\n",
    "    img = img.reshape((size, size))\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "    ckplus_images.append(img)\n",
    "    ckplus_labels.append(ckplus_dataset.iloc[i, 0])\n",
    "\n",
    "ckplus_dict = {\n",
    "    'images': ckplus_images,\n",
    "    'labels': ckplus_labels\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Kaggle tapakah68/facial-emotion-recognition Dataset and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_using_viola_johns_algorithm(img, classifier = 'haarcascade_frontalface_default.xml'):\n",
    "    # load in the haar cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier(cwd +'/' +classifier)\n",
    "\n",
    "    # convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # detect the faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    # draw a rectangle around the face\n",
    "    for (x, y, w, h) in faces:\n",
    "        # crop the image\n",
    "        img = img[y:y+h, x:x+w]\n",
    "        # resize the image to 48x48\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        # return the image\n",
    "        return img\n",
    "    \n",
    "# croped_image = crop_using_viola_johns_algorithm(cv2.imread(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/images/0/Anger.jpg'))\n",
    "# test the function\n",
    "# cv2.imwrite(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/images/0/Anger_cropped.jpg', croped_image.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load YOLOv3 weights and config file\n",
    "net = cv2.dnn.readNet(cwd + '/yolov3.weights', cwd + '/yolov3.cfg')\n",
    "\n",
    "with open(cwd + '/coco.names', 'r') as f:\n",
    "    classes = f.read().strip().split('\\n')\n",
    "def alternative_face_detector(img):\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward()\n",
    "    layer_names = net.getUnconnectedOutLayersNames()\n",
    "    detections = net.forward(layer_names)\n",
    "\n",
    "    for detection in detections:\n",
    "        for obj in detection:\n",
    "            scores = obj[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            if confidence > 0.5 and classes[classID] == \"person\":\n",
    "                return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/tapakah68/facial-emotion-recognition\n",
    "\n",
    "# crop images if they arent' already cropped\n",
    "\n",
    "if (os.listdir(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images') == []):\n",
    "\n",
    "    classifiers = ['haarcascade_frontalface_default.xml', 'haarcascade_frontalface_alt.xml', 'haarcascade_frontalface_alt2.xml', 'haarcascade_frontalface_alt_tree.xml','haarcascade_profileface.xml']\n",
    "\n",
    "    # go through the folders in the dataset/kaggle-facial-emotional-recognition-dataset \n",
    "    for folder in os.listdir(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/images'):\n",
    "        for img_name in os.listdir(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/images/' + folder):\n",
    "            img = cv2.imread(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/images/' + folder + '/' + img_name)\n",
    "            cropped_image = crop_using_viola_johns_algorithm(img)\n",
    "            if cropped_image is None:\n",
    "                print(\"no face detected\")\n",
    "                break\n",
    "            if cropped_image is None:\n",
    "                print(\"no face detected\")\n",
    "                break\n",
    "            if alternative_face_detector(cropped_image) == False:\n",
    "                for classifier in classifiers:\n",
    "                    cropped_image = crop_using_viola_johns_algorithm(img, classifier)\n",
    "                    if cropped_image is None:\n",
    "                        break\n",
    "                    if alternative_face_detector(cropped_image) == True:\n",
    "                        break\n",
    "                \n",
    "            if cropped_image is None:\n",
    "                print(\"no face detected\")\n",
    "                break\n",
    "            \n",
    "\n",
    "            # save the image\n",
    "            # if folder doesn't exist, create it\n",
    "            if not os.path.exists(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images'):\n",
    "                os.makedirs(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images')\n",
    "            if not os.path.exists(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images/' + folder):\n",
    "                os.makedirs(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images/' + folder)\n",
    "            \n",
    "\n",
    "                    # convert the image to grayscale\n",
    "            \n",
    "            cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imwrite(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images/' + folder + '/' + img_name, cropped_image)\n",
    "        # go through the images in the folder\n",
    "    \n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_label_for_string(label):\n",
    "    if label == 'Anger':\n",
    "        return 0\n",
    "    elif label == 'Disgust':\n",
    "        return 1\n",
    "    elif label == 'Fear':\n",
    "        return 2\n",
    "    elif label == 'Happy':\n",
    "        return 3\n",
    "    elif label == 'Sad':\n",
    "        return 4\n",
    "    elif label == 'Surprised':\n",
    "        return 5\n",
    "    elif label == 'Neutral':\n",
    "        return 6\n",
    "    elif label == 'Contempt':\n",
    "        return 7\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle images:  125\n",
      "kaggle labels:  125\n"
     ]
    }
   ],
   "source": [
    "# load in the cropped images\n",
    "# create a list of training and testing images\n",
    "\n",
    "kaggle_images = []\n",
    "kaggle_labels = []\n",
    "\n",
    "for folder in os.listdir(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images'):\n",
    "    for img_name in os.listdir(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images/' + folder):\n",
    "        img = cv2.imread(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images/' + folder + '/' + img_name)\n",
    "        if img is None:\n",
    "            print(\"img is none\")\n",
    "            break\n",
    "        kaggle_images.append(img)\n",
    "        # print(img_name)\n",
    "        # print(img_name.split('.')[0])\n",
    "        kaggle_labels.append(get_number_label_for_string(img_name.split('.')[0]))\n",
    "        \n",
    "print(\"kaggle images: \", len(kaggle_images))\n",
    "print(\"kaggle labels: \", len(kaggle_labels))\n",
    "\n",
    "kaggle_dict = {\n",
    "    'images': kaggle_images,\n",
    "    'labels': kaggle_labels\n",
    "}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # calc hog features using cv2.HOGDescriptor\n",
    "def generate_hog_features(image):\n",
    "    # hog = cv2.HOGDescriptor()\n",
    "    # # hog_features = hog.compute(image)\n",
    "     image = np.sqrt(image)\n",
    "\n",
    "     G_x = np.zeros_like(image, dtype=np.float32)\n",
    "     G_y = np.zeros_like(image, dtype=np.float32)\n",
    "\n",
    "     for y in range(1, image.shape[0] - 1):\n",
    "        for x in range(1, image.shape[1] - 1):\n",
    "            G_x[y, x] = image[y, x-1] - image[y, x+1]\n",
    "            G_y[y, x] = image[y-1, x] - image[y+1, x]\n",
    "    \n",
    "     G = np.sqrt(np.square(G_x) + np.square(G_y))\n",
    "     theta = np.arctan(G_y, G_x)\n",
    "\n",
    "     # divide the image into 8x8 cells\n",
    "     cells = np.zeros((8, 8, 8), dtype=np.float32)\n",
    "     # for each cell create a local 1-D histogram of gradient orientations that is sorted into 9 angular bins according to their gradient orientation evenly distributed over 0 to 180 degrees\n",
    "     for y in range(0, image.shape[0] - 8, 8):\n",
    "        for x in range(0, image.shape[1] - 8, 8):\n",
    "            for i in range(8):\n",
    "                for j in range(8):\n",
    "                    cells[i, j, int(theta[y+i, x+j] / 20)] += G[y+i, x+j]\n",
    "\n",
    "     # divide the cells within each angular bin divided into blocks with 3x3 cell in size\n",
    "     # for each block, normalize the histogram using L2-normalization approach\n",
    "     hog_features = []\n",
    "     for y in range(0, 6):\n",
    "        for x in range(0, 6):\n",
    "            block = cells[y:y+3, x:x+3].flatten()\n",
    "            block /= np.sqrt(np.sum(np.square(block)) + 1e-5)\n",
    "            hog_features.extend(block)\n",
    "     hog_features = np.array(hog_features)\n",
    "\n",
    "     hog_features = hog_features.flatten()\n",
    "     return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fold(train, test, classifier):\n",
    "    # https://www.researchgate.net/publication/221364666_Feature_reduction_using_Cuttlefish_Optimization_Algorithm\n",
    "    #CFA algorithm begins by keeping the feature locations (indices) of a particular dataset in a RankedArray list as follows: RankedArray = [0, 1, 2, …, L − 1], where L represents the feature size. \n",
    "    #After that, it initializes a population (P) with N random solutions, so that each solution Pi is linked with two subsets: SelectedFeatures and UnselectedFeatures, where SelectedFeatures ⊂ RankedArray, UnselectedFeatures ⊂ RankedArray, and SelectedFeatures ⋂ UnselectedFeatures = Ø\n",
    "\n",
    "    # ranked_list variable has the indices of the features in the dataset from 0 to image feature size - 1\n",
    "    ranked_list = np.arange(train['images'][0].shape[0])\n",
    "\n",
    "    # train and test has following structure {'images': [], 'labels': []}\n",
    "\n",
    "    # solution has the following structure list of solution dictionaries which contain the indices of the selected and unselected features\n",
    "    solutions = []\n",
    "    N = random.randint(1, train['images'][0].shape[0])\n",
    "    for random_solution in range(0, N):\n",
    "        # randomly select the indices of the features\n",
    "        indices_for_selected_features = np.random.choice(ranked_list, N)\n",
    "        # using the indices_for_selected_features take the indices and put those features aat those indices in the selected_features array\n",
    "        selected_image_features_indices = [indices_for_selected_features]\n",
    "        unselected_image_features_indices = np.setdiff1d(ranked_list, selected_image_features_indices)\n",
    "        solution = {\n",
    "            'selected_features_indices': selected_image_features_indices,\n",
    "            'unselected_features_indices': unselected_image_features_indices,\n",
    "        }\n",
    "        solutions.append(solution)\n",
    "\n",
    "\n",
    "    # go through each solution in the solutions list and calculate the goodness of the solution\n",
    "    solutions_with_goodness = []\n",
    "    for solution in solutions:\n",
    "        # calculate the goodness of the solution\n",
    "        # goodness = 1 / (1 + error)\n",
    "        # error = 1 - accuracy\n",
    "        # accuracy = svm.score(features[solution[0]], features[solution[1]])\n",
    "\n",
    "        # get the features at the selected_features_indices\n",
    "        train_images_with_selected_features =[]\n",
    "        for i in range(0, train['images'].shape[0]):\n",
    "            train_images_with_selected_features.append(train['images'][i][solution['selected_features_indices']])\n",
    "        test_images_with_selected_features = []\n",
    "        for i in range(0, test['images'].shape[0]):\n",
    "            test_images_with_selected_features.append(test['images'][i][solution['selected_features_indices']])\n",
    "\n",
    "        classifier.fit(train_images_with_selected_features, train['labels'])\n",
    "        solution['goodness'] = 1 / (1 + (1 - svm.score(train['images'][solution['selected_features_indices']], train['labels'])))\n",
    "        # TODO maybe change this to use the test accuracy for the goodness\n",
    "        test_accuracy = svm.score(test_images_with_selected_features, test['labels'])\n",
    "        print(\"test accuracy: \", test_accuracy)\n",
    "        solutions_with_goodness.append(solution)\n",
    "\n",
    "    # sort the solutions_with_goodness list in descending order of goodness\n",
    "    solutions_with_goodness.sort(key=lambda x: x['goodness'], reverse=True)\n",
    "\n",
    "    best_solution = solutions_with_goodness[0]\n",
    "\n",
    "    # randomly delete 10% of the features from the selected_features_indices\n",
    "    best_solution['selected_features_indices'] = np.random.choice(best_solution['selected_features_indices'], int(best_solution['selected_features_indices'].shape[0] * 0.9))\n",
    "    \n",
    "    # while the stopping criteria is not met, the algorithm performs the following steps:   \n",
    "    stoping_criteria = 0\n",
    "    while stoping_criteria !=100:\n",
    "        # calculat the CFA of each solution within the population_of_solutions\n",
    "        # for each solution within the population_of_solutions, calculate the CFA\n",
    "        K = random.randint(0,N/2)\n",
    "        for i in range(0, K-1):\n",
    "            r = random.randint(0,solutions_with_goodness[i][\"selected_image_features_indices\"].shape[0]-1)\n",
    "            v = solutions_with_goodness[i][\"selected_image_features_indices\"] - r\n",
    "            reflection = random.sample(solutions_with_goodness[i][\"selected_image_features_indices\"], r)\n",
    "            visibility = random.sample(solutions_with_goodness[i][\"unselected_features_indices\"], v)\n",
    "            # new subset union of reflection and visibility\n",
    "            newSubset = reflection + visibility\n",
    "            # evaluate new subset using the svm\n",
    "            # get the features at the selected_features_indices\n",
    "            train_images_with_selected_features =[]\n",
    "            for i in range(0, train['images'].shape[0]):\n",
    "                train_images_with_selected_features.append(train['images'][i][newSubset])\n",
    "            test_images_with_selected_features = []\n",
    "            for i in range(0, test['images'].shape[0]):\n",
    "                test_images_with_selected_features.append(test['images'][i][newSubset])\n",
    "\n",
    "            classifier.fit(train_images_with_selected_features, train['labels'])\n",
    "            goodness = 1 / (1 + (1 - svm.score(train['images'][newSubset], train['labels'])))\n",
    "            # TODO maybe change this to use the test accuracy for the goodness\n",
    "            test_accuracy = svm.score(test_images_with_selected_features, test['labels'])\n",
    "            print(\"test accuracy: \", test_accuracy)\n",
    "            if goodness > solutions_with_goodness[i]['goodness']:\n",
    "                solutions_with_goodness[i]['goodness'] = goodness\n",
    "                solutions_with_goodness[i]['selected_features_indices'] = newSubset\n",
    "                solutions_with_goodness[i]['unselected_features_indices'] = np.setdiff1d(ranked_list, newSubset)\n",
    "            if goodness > best_solution['goodness']:\n",
    "                best_solution = solutions_with_goodness[i]\n",
    "        \n",
    "        newSubset = best_solution\n",
    "        T = 5\n",
    "        for i in range(0, T-1):\n",
    "            # randomly exchange 10% of the features between the selected and unselected features of the newSubset\n",
    "            newSubset = np.random.choice(newSubset['selected_features_indices'], int(newSubset['selected_features_indices'].shape[0] * 0.9))\n",
    "\n",
    "            # evaluate new subset using the svm\n",
    "            # get the features at the selected_features_indices\n",
    "            train_images_with_selected_features =[]\n",
    "            for i in range(0, train['images'].shape[0]):\n",
    "                train_images_with_selected_features.append(train['images'][i][newSubset])\n",
    "            test_images_with_selected_features = []\n",
    "            for i in range(0, test['images'].shape[0]):\n",
    "                test_images_with_selected_features.append(test['images'][i][newSubset])\n",
    "\n",
    "            classifier.fit(train_images_with_selected_features, train['labels'])\n",
    "            goodness = 1 / (1 + (1 - svm.score(train['images'][newSubset], train['labels'])))\n",
    "            # TODO maybe change this to use the test accuracy for the goodness\n",
    "            test_accuracy = svm.score(test_images_with_selected_features, test['labels'])\n",
    "            print(\"test accuracy: \", test_accuracy)\n",
    "            if goodness > best_solution['goodness']:\n",
    "                newSubset[\"goodness\"] = goodness\n",
    "                best_solution = newSubset\n",
    "        m = 5\n",
    "        size = best_solution.shape[0]\n",
    "        for i in range(0, m-1):\n",
    "            # randomly delete 10% of the features from the selected_features_indices\n",
    "            new_subset = np.random.choice(best_solution['selected_features_indices'], int(best_solution['selected_features_indices'].shape[0] * 0.9))\n",
    "            # evaluate new subset using the svm\n",
    "            # get the features at the selected_features_indices\n",
    "            train_images_with_selected_features =[]\n",
    "            for i in range(0, train['images'].shape[0]):\n",
    "                train_images_with_selected_features.append(train['images'][i][new_subset])\n",
    "            test_images_with_selected_features = []\n",
    "            for i in range(0, test['images'].shape[0]):\n",
    "                test_images_with_selected_features.append(test['images'][i][new_subset])\n",
    "\n",
    "            classifier.fit(train_images_with_selected_features, train['labels'])\n",
    "            goodness = 1 / (1 + (1 - svm.score(train['images'][new_subset], train['labels'])))\n",
    "            # TODO maybe change this to use the test accuracy for the goodness\n",
    "            test_accuracy = svm.score(test_images_with_selected_features, test['labels'])\n",
    "            print(\"test accuracy: \", test_accuracy)\n",
    "            if goodness > best_solution['goodness']:\n",
    "                new_subset[\"goodness\"] = goodness\n",
    "                best_solution = new_subset\n",
    "            \n",
    "            for i in range(0, K):\n",
    "                # randomly generate newsubset\n",
    "                new_subset = np.random.choice(ranked_list, N)\n",
    "                # evaluate new subset using the svm\n",
    "                # get the features at the selected_features_indices\n",
    "                train_images_with_selected_features =[]\n",
    "                for i in range(0, train['images'].shape[0]):\n",
    "                    train_images_with_selected_features.append(train['images'][i][new_subset])\n",
    "                test_images_with_selected_features = []\n",
    "                for i in range(0, test['images'].shape[0]):\n",
    "                    test_images_with_selected_features.append(test['images'][i][new_subset])\n",
    "                \n",
    "                classifier.fit(train_images_with_selected_features, train['labels'])\n",
    "                goodness = 1 / (1 + (1 - svm.score(train['images'][new_subset], train['labels'])))\n",
    "            #     # TODO maybe change this to use the test accuracy for the goodness\n",
    "                test_accuracy = svm.score(test_images_with_selected_features, test['labels'])\n",
    "                print(\"test accuracy: \", test_accuracy)\n",
    "                if goodness > solutions_with_goodness[i]['goodness']:\n",
    "                    solutions_with_goodness[i]['goodness'] = goodness\n",
    "                    solutions_with_goodness[i]['selected_features_indices'] = new_subset\n",
    "                    solutions_with_goodness[i]['unselected_features_indices'] = np.setdiff1d(ranked_list, new_subset)\n",
    "                if goodness > best_solution['goodness']:\n",
    "                    best_solution = newSubset\n",
    "                    best_solution['goodness'] = goodness\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "                \n",
    "\n",
    "           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(dataset, classifier):\n",
    "    # split the dataset into five fold cross validation\n",
    "    # create a list of the indexes of the dataset\n",
    "    # shuffle the indexes\n",
    "    # split the indexes into five folds\n",
    "    print(\"dataset: \")\n",
    "    # print the keys in the dataset dictionary\n",
    "    print(dataset.keys())\n",
    "\n",
    "    folds_images = np.array_split(dataset[\"images\"], 5)\n",
    "    folds_labels = np.array_split(dataset[\"labels\"], 5)\n",
    "    folds = []\n",
    "    for i in range(0, len(folds_images)):\n",
    "        fold = {\n",
    "            'images': folds_images[i],\n",
    "            'labels': folds_labels[i]\n",
    "        }\n",
    "        folds.append(fold)\n",
    "    \n",
    "    # create a list of the accuracies for each fold\n",
    "    all_accuracy = [] \n",
    "    # go through each fold\n",
    "    for i in range(0, len(folds)):\n",
    "        testing = folds[i]\n",
    "        ## all the other folds are training\n",
    "        training = []\n",
    "        for j in range(0, len(folds)):\n",
    "            if j != i:\n",
    "                training.append(folds[j])\n",
    "        # flatten the training folds\n",
    "        training = np.array(training).flatten()\n",
    "\n",
    "\n",
    "        train_image_features = []\n",
    "        train_image_labels = []\n",
    "        test_image_features = []\n",
    "        test_image_labels = []\n",
    "\n",
    "        print(\"training\")\n",
    "        print(training)\n",
    "\n",
    "        for image in training[\"images\"]:\n",
    "            print(\"image: \", image)\n",
    "            # get the image\n",
    "            img = dataset['images'][image]\n",
    "            # get the label\n",
    "            label = dataset['labels'][image]\n",
    "            # get the hog features\n",
    "            hog_features = generate_hog_features(img)\n",
    "            # add the hog features to the dataset\n",
    "            train_image_features.append(hog_features)\n",
    "            train_image_labels.append(label)\n",
    "        for image in testing[\"images\"]:\n",
    "            # get the image\n",
    "            img = dataset['images'][image]\n",
    "            # get the label\n",
    "            label = dataset['labels'][image]\n",
    "            # get the hog features\n",
    "            hog_features = generate_hog_features(img)\n",
    "            # add the hog features to the dataset\n",
    "            test_image_features.append(hog_features)\n",
    "            test_image_labels.append(label)\n",
    "        \n",
    "        train = {\n",
    "            'images': train_image_features,\n",
    "            'labels': train_image_labels\n",
    "        }\n",
    "        test = {\n",
    "            'images': test_image_features,\n",
    "            'labels': test_image_labels\n",
    "        }\n",
    "        process_fold(train,test, classifier)\n",
    "        \n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: \n",
      "dict_keys(['images', 'labels'])\n",
      "training\n",
      "[{'images': array([[[ 13.      ,   8.625   ,   8.25    , ...,  40.5     ,\n",
      "           43.125   ,  45.      ],\n",
      "         [ 10.5     ,   8.078125,   9.109375, ...,  30.890625,\n",
      "           33.984375,  36.25    ],\n",
      "         [  8.625   ,   8.3125  ,  10.328125, ...,  24.609375,\n",
      "           26.15625 ,  29.125   ],\n",
      "         ...,\n",
      "         [ 23.125   ,  22.03125 ,  22.6875  , ...,   9.3125  ,\n",
      "           12.921875,  18.625   ],\n",
      "         [ 24.25    ,  23.390625,  22.21875 , ...,   4.109375,\n",
      "            8.      ,  14.875   ],\n",
      "         [ 18.      ,  23.      ,  23.      , ...,   5.125   ,\n",
      "            9.25    ,  13.      ]],\n",
      "\n",
      "        [[ 52.      ,  35.75    ,  16.25    , ...,  41.5     ,\n",
      "           58.75    ,  65.      ],\n",
      "         [ 46.375   ,  23.484375,   6.09375 , ...,  38.53125 ,\n",
      "           58.125   ,  61.25    ],\n",
      "         [ 27.625   ,  10.359375,   0.      , ...,  28.78125 ,\n",
      "           49.921875,  59.375   ],\n",
      "         ...,\n",
      "         [ 45.875   ,  44.703125,  43.859375, ...,  48.359375,\n",
      "           47.609375,  48.      ],\n",
      "         [ 42.5     ,  42.96875 ,  43.390625, ...,  48.828125,\n",
      "           48.5     ,  49.125   ],\n",
      "         [ 40.      ,  41.25    ,  42.375   , ...,  50.      ,\n",
      "           50.375   ,  51.      ]],\n",
      "\n",
      "        [[ 84.      ,  85.25    ,  82.625   , ..., 111.      ,\n",
      "          110.25    , 109.      ],\n",
      "         [ 84.      ,  85.25    ,  74.421875, ..., 111.46875 ,\n",
      "          110.484375, 109.625   ],\n",
      "         [ 83.625   ,  84.40625 ,  72.734375, ..., 111.703125,\n",
      "          110.71875 , 109.625   ],\n",
      "         ...,\n",
      "         [ 73.25    ,  73.953125,  75.734375, ...,  81.75    ,\n",
      "           88.21875 ,  90.25    ],\n",
      "         [ 73.25    ,  74.65625 ,  76.15625 , ...,  91.3125  ,\n",
      "           91.453125,  89.5     ],\n",
      "         [ 72.      ,  75.75    ,  77.25    , ...,  91.625   ,\n",
      "           90.125   ,  87.      ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 70.      ,  71.875   ,  71.125   , ...,  87.25    ,\n",
      "           87.625   ,  87.      ],\n",
      "         [ 73.75    ,  73.28125 ,  66.203125, ...,  90.0625  ,\n",
      "           88.09375 ,  88.25    ],\n",
      "         [ 76.375   ,  72.390625,  62.5     , ...,  87.0625  ,\n",
      "           85.65625 ,  86.75    ],\n",
      "         ...,\n",
      "         [ 61.25    ,  62.03125 ,  63.0625  , ...,  29.53125 ,\n",
      "           41.53125 ,  52.625   ],\n",
      "         [ 63.125   ,  62.03125 ,  62.359375, ...,  11.15625 ,\n",
      "           20.34375 ,  26.75    ],\n",
      "         [ 65.      ,  63.125   ,  62.75    , ...,  18.5     ,\n",
      "           19.25    ,   3.      ]],\n",
      "\n",
      "        [[132.      ,  60.125   ,  15.125   , ..., 176.375   ,\n",
      "          180.875   , 184.      ],\n",
      "         [ 84.5     ,  42.703125,  14.109375, ..., 173.71875 ,\n",
      "          179.39062 , 182.125   ],\n",
      "         [ 41.      ,  24.515625,  11.671875, ..., 169.82812 ,\n",
      "          178.73438 , 181.      ],\n",
      "         ...,\n",
      "         [143.125   , 145.15625 , 146.5625  , ..., 159.53125 ,\n",
      "          159.34375 , 159.5     ],\n",
      "         [141.625   , 142.95312 , 143.375   , ..., 160.65625 ,\n",
      "          160.32812 , 160.25    ],\n",
      "         [141.      , 140.375   , 139.625   , ..., 161.75    ,\n",
      "          160.25    , 159.      ]],\n",
      "\n",
      "        [[ 76.      ,  75.375   ,  73.125   , ...,  98.      ,\n",
      "          101.375   , 102.      ],\n",
      "         [ 76.      ,  73.03125 ,  68.90625 , ...,  99.09375 ,\n",
      "          100.828125,  99.5     ],\n",
      "         [ 74.5     ,  71.53125 ,  64.3125  , ...,  93.421875,\n",
      "           98.8125  ,  99.125   ],\n",
      "         ...,\n",
      "         [ 54.625   ,  55.09375 ,  55.703125, ...,  48.140625,\n",
      "           50.765625,  55.375   ],\n",
      "         [ 54.625   ,  54.625   ,  55.375   , ...,  50.71875 ,\n",
      "           52.078125,  53.875   ],\n",
      "         [ 54.      ,  54.      ,  54.75    , ...,  49.625   ,\n",
      "           56.375   ,  57.      ]]], dtype=float32), 'labels': array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6])}\n",
      " {'images': array([[[ 98.      ,  99.25    , 100.      , ...,  81.75    ,\n",
      "          109.125   , 111.      ],\n",
      "         [ 98.625   ,  99.875   , 100.15625 , ...,  79.71875 ,\n",
      "          105.921875, 112.875   ],\n",
      "         [100.125   , 100.203125,  99.640625, ...,  71.328125,\n",
      "           96.40625 , 116.25    ],\n",
      "         ...,\n",
      "         [ 65.5     ,  66.515625,  67.78125 , ..., 111.875   ,\n",
      "           68.234375,  69.875   ],\n",
      "         [ 64.      ,  65.015625,  66.140625, ..., 131.65625 ,\n",
      "           90.265625,  71.75    ],\n",
      "         [ 64.      ,  64.625   ,  65.75    , ..., 164.      ,\n",
      "          124.25    ,  78.      ]],\n",
      "\n",
      "        [[ 62.      ,  23.25    ,   0.      , ...,  99.      ,\n",
      "           99.75    , 101.      ],\n",
      "         [ 45.75    ,  17.546875,   0.390625, ..., 100.640625,\n",
      "          100.921875, 101.      ],\n",
      "         [ 30.75    ,  11.921875,   0.390625, ..., 100.59375 ,\n",
      "          101.296875, 101.375   ],\n",
      "         ...,\n",
      "         [ 60.25    ,  67.515625,  77.78125 , ...,  74.765625,\n",
      "           74.15625 ,  60.25    ],\n",
      "         [ 49.      ,  50.40625 ,  77.6875  , ...,  71.53125 ,\n",
      "           78.234375,  71.125   ],\n",
      "         [ 64.      ,  52.125   ,  81.75    , ...,  57.      ,\n",
      "           70.5     ,  88.      ]],\n",
      "\n",
      "        [[106.      , 110.375   , 114.875   , ..., 137.375   ,\n",
      "          136.625   , 136.      ],\n",
      "         [107.875   , 113.03125 , 115.65625 , ..., 136.59375 ,\n",
      "          136.54688 , 137.875   ],\n",
      "         [111.625   , 114.671875, 115.609375, ..., 137.0625  ,\n",
      "          137.4375  , 139.      ],\n",
      "         ...,\n",
      "         [ 51.25    ,  39.53125 ,  34.609375, ...,  39.296875,\n",
      "           59.828125,  86.625   ],\n",
      "         [ 62.875   ,  46.9375  ,  34.28125 , ...,  35.875   ,\n",
      "           57.390625,  83.25    ],\n",
      "         [ 81.      ,  60.375   ,  36.      , ...,  37.125   ,\n",
      "           60.75    ,  87.      ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 18.      ,  20.5     ,  19.375   , ...,  60.875   ,\n",
      "           51.5     ,  44.      ],\n",
      "         [ 18.625   ,  18.390625,  16.796875, ...,  42.4375  ,\n",
      "           36.109375,  35.25    ],\n",
      "         [ 19.375   ,  16.5625  ,  14.96875 , ...,  36.0625  ,\n",
      "           28.890625,  30.375   ],\n",
      "         ...,\n",
      "         [ 67.25    ,  67.71875 ,  68.515625, ...,  87.734375,\n",
      "           85.203125,  84.5     ],\n",
      "         [ 66.875   ,  66.640625,  67.296875, ...,  87.3125  ,\n",
      "           85.34375 ,  84.875   ],\n",
      "         [ 65.      ,  64.375   ,  65.5     , ...,  85.75    ,\n",
      "           84.25    ,  83.      ]],\n",
      "\n",
      "        [[ 82.      ,  40.75    ,  13.75    , ..., 112.25    ,\n",
      "          112.25    , 111.      ],\n",
      "         [ 83.25    ,  42.390625,  16.796875, ..., 112.796875,\n",
      "          111.859375, 111.      ],\n",
      "         [ 85.5     ,  47.6875  ,  21.25    , ..., 114.671875,\n",
      "          113.59375 , 112.5     ],\n",
      "         ...,\n",
      "         [ 66.75    ,  68.3125  ,  71.59375 , ...,  87.71875 ,\n",
      "           93.390625,  89.875   ],\n",
      "         [ 67.125   ,  69.15625 ,  72.015625, ...,  88.84375 ,\n",
      "           97.609375,  93.625   ],\n",
      "         [ 69.      ,  70.25    ,  67.25    , ...,  90.25    ,\n",
      "           99.25    ,  98.      ]],\n",
      "\n",
      "        [[ 40.      ,  31.25    ,  29.375   , ...,  47.75    ,\n",
      "           56.75    ,  63.      ],\n",
      "         [ 36.875   ,  32.03125 ,  28.515625, ...,  55.015625,\n",
      "           65.1875  ,  60.5     ],\n",
      "         [ 33.875   ,  31.375   ,  26.59375 , ...,  57.171875,\n",
      "           66.921875,  60.125   ],\n",
      "         ...,\n",
      "         [  1.375   ,   0.75    ,   1.59375 , ...,  18.75    ,\n",
      "            8.71875 ,   7.625   ],\n",
      "         [  0.625   ,   0.234375,   0.9375  , ...,  14.015625,\n",
      "            5.390625,   6.875   ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,  14.875   ,\n",
      "            8.125   ,  10.      ]]], dtype=float32), 'labels': array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6])}\n",
      " {'images': array([[[ 15.      ,   5.625   ,   3.75    , ...,   8.25    ,\n",
      "           28.125   ,  55.      ],\n",
      "         [  5.625   ,   2.109375,   3.046875, ...,  23.796875,\n",
      "           23.75    ,  25.625   ],\n",
      "         [  0.      ,   0.      ,   1.921875, ...,  32.703125,\n",
      "           22.109375,   5.      ],\n",
      "         ...,\n",
      "         [ 34.      ,  35.484375,  36.234375, ...,  45.515625,\n",
      "           44.296875,  40.625   ],\n",
      "         [ 35.125   ,  35.671875,  35.859375, ..., 110.625   ,\n",
      "           98.15625 ,  66.125   ],\n",
      "         [ 37.      ,  36.375   ,  35.625   , ..., 218.75    ,\n",
      "          186.125   , 108.      ]],\n",
      "\n",
      "        [[ 49.      ,  49.625   ,  50.      , ...,  66.5     ,\n",
      "           63.875   ,  62.      ],\n",
      "         [ 49.625   ,  49.859375,  45.3125  , ...,  67.59375 ,\n",
      "           66.609375,  65.125   ],\n",
      "         [ 51.875   ,  47.65625 ,  38.890625, ...,  67.96875 ,\n",
      "           68.390625,  67.375   ],\n",
      "         ...,\n",
      "         [ 44.      ,  45.09375 ,  45.796875, ...,  54.625   ,\n",
      "           55.046875,  55.75    ],\n",
      "         [ 43.25    ,  44.8125  ,  46.078125, ...,  55.890625,\n",
      "           55.609375,  55.375   ],\n",
      "         [ 42.      ,  45.125   ,  46.625   , ...,  57.375   ,\n",
      "           56.625   ,  56.      ]],\n",
      "\n",
      "        [[112.      , 113.875   , 115.375   , ..., 128.75    ,\n",
      "          131.375   , 132.      ],\n",
      "         [112.625   , 112.9375  , 113.734375, ..., 129.0625  ,\n",
      "          132.625   , 133.25    ],\n",
      "         [112.25    , 112.796875, 113.453125, ..., 127.984375,\n",
      "          131.6875  , 133.25    ],\n",
      "         ...,\n",
      "         [ 91.625   ,  92.953125,  93.1875  , ...,  43.1875  ,\n",
      "           53.59375 ,  73.75    ],\n",
      "         [ 90.125   ,  91.21875 ,  92.15625 , ...,  37.28125 ,\n",
      "           44.171875,  59.875   ],\n",
      "         [ 87.      ,  88.875   ,  90.75    , ...,  44.      ,\n",
      "           45.5     ,  53.      ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[114.      ,  78.375   ,  48.      , ...,  55.5     ,\n",
      "           58.875   ,  72.      ],\n",
      "         [104.625   ,  72.125   ,  41.046875, ...,  45.1875  ,\n",
      "           52.546875,  58.25    ],\n",
      "         [ 95.625   ,  62.1875  ,  32.9375  , ...,  31.96875 ,\n",
      "           39.046875,  42.875   ],\n",
      "         ...,\n",
      "         [127.125   , 128.0625  , 129.79688 , ..., 151.32812 ,\n",
      "          152.64062 , 152.25    ],\n",
      "         [125.25    , 127.359375, 129.375   , ..., 152.35938 ,\n",
      "          152.26562 , 150.      ],\n",
      "         [124.      , 129.625   , 131.875   , ..., 153.375   ,\n",
      "          151.875   , 150.      ]],\n",
      "\n",
      "        [[ 78.      ,  77.375   ,  77.375   , ...,  66.5     ,\n",
      "           85.25    ,  94.      ],\n",
      "         [ 76.75    ,  76.90625 ,  77.609375, ...,  57.515625,\n",
      "           80.484375,  92.75    ],\n",
      "         [ 76.375   ,  76.53125 ,  76.390625, ...,  45.375   ,\n",
      "           69.609375,  93.125   ],\n",
      "         ...,\n",
      "         [ 77.25    ,  77.640625,  78.296875, ...,  87.953125,\n",
      "           87.953125,  86.625   ],\n",
      "         [ 76.875   ,  77.5     ,  78.296875, ...,  87.296875,\n",
      "           87.859375,  87.      ],\n",
      "         [ 75.      ,  75.625   ,  77.125   , ...,  83.625   ,\n",
      "           85.125   ,  87.      ]],\n",
      "\n",
      "        [[ 95.      ,  95.      , 109.25    , ..., 144.5     ,\n",
      "           89.375   ,  95.      ],\n",
      "         [ 95.625   ,  92.890625, 121.4375  , ..., 156.14062 ,\n",
      "           97.265625,  93.125   ],\n",
      "         [ 96.      ,  88.34375 , 130.95312 , ..., 176.57812 ,\n",
      "          115.59375 ,  92.      ],\n",
      "         ...,\n",
      "         [ 74.875   ,  76.125   ,  78.328125, ...,  87.140625,\n",
      "           85.03125 ,  85.5     ],\n",
      "         [ 61.      ,  69.515625,  98.71875 , ...,  92.390625,\n",
      "           85.78125 ,  71.25    ],\n",
      "         [ 41.      ,  61.625   , 135.125   , ...,  95.125   ,\n",
      "           88.75    ,  75.      ]]], dtype=float32), 'labels': array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " {'images': array([[[  5.      ,   6.25    ,   4.375   , ...,  38.125   ,\n",
      "           75.25    ,  99.      ],\n",
      "         [  1.875   ,   2.734375,   2.96875 , ...,  21.5625  ,\n",
      "           54.46875 ,  88.375   ],\n",
      "         [  0.75    ,   0.90625 ,   1.984375, ...,   7.265625,\n",
      "           38.0625  ,  82.75    ],\n",
      "         ...,\n",
      "         [  0.375   ,   4.046875,  14.21875 , ...,  66.890625,\n",
      "           69.421875,  72.      ],\n",
      "         [  3.      ,  10.1875  ,  16.984375, ...,  65.90625 ,\n",
      "           68.296875,  70.875   ],\n",
      "         [  8.      ,  16.75    ,  14.875   , ...,  67.625   ,\n",
      "           68.375   ,  69.      ]],\n",
      "\n",
      "        [[ 25.      ,  23.75    ,  24.5     , ...,  34.      ,\n",
      "           33.625   ,  33.      ],\n",
      "         [ 25.625   ,  23.984375,  23.796875, ...,  32.359375,\n",
      "           32.21875 ,  32.375   ],\n",
      "         [ 25.625   ,  23.984375,  23.515625, ...,  30.8125  ,\n",
      "           30.671875,  32.      ],\n",
      "         ...,\n",
      "         [115.625   , 104.296875,  87.1875  , ..., 146.60938 ,\n",
      "          145.29688 , 144.125   ],\n",
      "         [ 86.75    ,  74.953125,  63.1875  , ..., 145.625   ,\n",
      "          144.3125  , 143.375   ],\n",
      "         [ 53.      ,  54.875   ,  72.875   , ..., 143.75    ,\n",
      "          143.375   , 144.      ]],\n",
      "\n",
      "        [[ 88.      ,  79.875   ,  62.625   , ..., 117.25    ,\n",
      "          118.75    , 120.      ],\n",
      "         [ 89.875   ,  74.71875 ,  53.25    , ..., 117.40625 ,\n",
      "          118.671875, 118.75    ],\n",
      "         [ 85.75    ,  67.3125  ,  44.15625 , ..., 116.234375,\n",
      "          118.0625  , 118.375   ],\n",
      "         ...,\n",
      "         [  9.625   ,  11.96875 ,  16.      , ...,  27.40625 ,\n",
      "           37.109375,  46.25    ],\n",
      "         [ 11.125   ,  15.578125,  22.28125 , ...,  29.796875,\n",
      "           40.203125,  48.875   ],\n",
      "         [ 13.      ,  18.625   ,  26.5     , ...,  30.5     ,\n",
      "           41.375   ,  52.      ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 76.      ,  53.5     ,  36.625   , ..., 109.75    ,\n",
      "          108.25    , 107.      ],\n",
      "         [ 63.5     ,  44.515625,  33.265625, ..., 110.296875,\n",
      "          109.5     , 108.25    ],\n",
      "         [ 50.375   ,  37.484375,  30.03125 , ..., 110.90625 ,\n",
      "          110.25    , 109.      ],\n",
      "         ...,\n",
      "         [ 75.875   ,  77.4375  ,  78.375   , ...,  89.46875 ,\n",
      "           89.234375,  89.      ],\n",
      "         [ 74.75    ,  76.78125 ,  77.296875, ...,  86.890625,\n",
      "           87.921875,  88.625   ],\n",
      "         [ 76.      ,  77.25    ,  76.125   , ...,  84.625   ,\n",
      "           86.125   ,  88.      ]],\n",
      "\n",
      "        [[114.      ,  97.125   ,  60.375   , ..., 144.5     ,\n",
      "          142.25    , 141.      ],\n",
      "         [121.5     ,  80.796875,  45.6875  , ..., 143.79688 ,\n",
      "          144.35938 , 143.5     ],\n",
      "         [114.75    ,  62.09375 ,  30.078125, ..., 144.92188 ,\n",
      "          146.1875  , 146.5     ],\n",
      "         ...,\n",
      "         [ 94.75    ,  96.078125,  97.15625 , ..., 166.15625 ,\n",
      "          134.98438 , 121.625   ],\n",
      "         [ 86.125   , 103.625   , 130.15625 , ..., 216.40625 ,\n",
      "          184.10938 , 168.875   ],\n",
      "         [ 78.      , 120.5     , 186.875   , ..., 253.125   ,\n",
      "          250.125   , 247.      ]],\n",
      "\n",
      "        [[101.      , 101.625   , 100.875   , ...,  94.      ,\n",
      "          115.75    , 117.      ],\n",
      "         [ 99.75    , 100.765625, 100.953125, ...,  88.0625  ,\n",
      "          110.984375, 115.75    ],\n",
      "         [100.125   , 101.375   , 101.984375, ...,  73.25    ,\n",
      "           98.703125, 116.125   ],\n",
      "         ...,\n",
      "         [ 67.875   ,  69.828125,  72.40625 , ...,  72.21875 ,\n",
      "           71.234375,  72.875   ],\n",
      "         [ 66.      ,  68.65625 ,  70.953125, ...,  71.328125,\n",
      "           64.859375,  66.5     ],\n",
      "         [ 66.      ,  67.875   ,  69.      , ...,  76.25    ,\n",
      "           60.875   ,  59.      ]]], dtype=float32), 'labels': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5])}                                                                                                      ]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/kf7mxe/School/2023/Computer Vision/project/project_phase_1_checkpoint.ipynb Cell 17\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# train with the ckplus_dataset with the svm classifier\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#create a support vector machine classifier using sklearn\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m svm_classifier \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mSVC()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train_test(ckplus_dict, svm_classifier)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# train with the kaggle dataset with the svm classifier\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#create a support vector machine classifier using sklearn\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m svm_classifier \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mSVC()\n",
      "\u001b[1;32m/home/kf7mxe/School/2023/Computer Vision/project/project_phase_1_checkpoint.ipynb Cell 17\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mprint\u001b[39m(training)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m training[\u001b[39m\"\u001b[39;49m\u001b[39mimages\u001b[39;49m\u001b[39m\"\u001b[39;49m]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mimage: \u001b[39m\u001b[39m\"\u001b[39m, image)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kf7mxe/School/2023/Computer%20Vision/project/project_phase_1_checkpoint.ipynb#X23sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39m# get the image\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "\n",
    "# train with the ckplus_dataset with the svm classifier\n",
    "\n",
    "#create a support vector machine classifier using sklearn\n",
    "svm_classifier = svm.SVC()\n",
    "\n",
    "train_test(ckplus_dict, svm_classifier)\n",
    "\n",
    "\n",
    "# train with the kaggle dataset with the svm classifier\n",
    "\n",
    "#create a support vector machine classifier using sklearn\n",
    "svm_classifier = svm.SVC()\n",
    "\n",
    "train_test(kaggle_dict, svm_classifier)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Computer_Vision-ERhKS5AB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
