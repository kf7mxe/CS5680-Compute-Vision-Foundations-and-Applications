{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Phase 2\n",
    "\n",
    "For this phase I was planning on having improved the algorithm and have it working better. I wasn't quite able to get the working but I was able to get any improvements added but I was able to replicate the algorithm as far as I understand the reading the paper\n",
    "\n",
    "I was able to finish the training process and the cuttlfish algorithm. I implemented five fold cross validation to use due to the low amount of data that we have just as the paper did. Where you break up the training data into five folds and one fold is used for the testing data and the rest is used for training and the testing fold is switched to a different fold and the other test fold is added to the training and then it is trained on that data as well to get an average of of performance. \n",
    "\n",
    "I also implemented the cuttlefish algorithm by first generating a population of possible solutions with random different features then you get the \"goodness\" or accuracy of the model by training a SVM or Support Vector Machine on every solution in the population then you take the top 10% of the population and use them to generate a new population by randomly selecting two of the top 10% and then randomly selecting a feature from each of them and then combining them to make a new solution. Then you get the reflection and the visibility of the new solution and if the new solution is better than the best solution then you replace the best solution with the new solution. \n",
    "Then you exchange 10% of the population between the selected and unselected features in the solution and then you check the accuracy and if it is better than the best solution then you replace the best solution with the new solution. Then you generate a randomly generate subset and test it and if it is better than the best solution then you replace the best solution with the new solution. Then you keep repeating this in a loop until you reach the maximum number of iterations or you reach the maximum number of iterations without improving the best solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cwd = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets used\n",
    "* https://www.kaggle.com/datasets/tapakah68/facial-emotion-recognition\n",
    "*https://www.kaggle.com/datasets/davilsena/ckdataset\n",
    "\n",
    "\n",
    "\n",
    "### Unable to use Dataset\n",
    "Not able to use the JAFFE dataset due to restrictions on the dataset. Including the restriction of not being able to be used for homework, undergraduate projects and course projects. Unless there is another way to access it but I wasn't able to find any other way to access it.\n",
    "https://zenodo.org/records/3451524\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CK+ Dataset csv file\n",
    "\n",
    "0: anger\n",
    "1: disgust\n",
    "2: fear\n",
    "3: happy\n",
    "4: sad\n",
    "5: surprise\n",
    "6: neutral\n",
    "7: contempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emotion                                             pixels     Usage\n",
      "0        6  36 39 35 25 19 11 8 7 3 13 15 9 21 57 75 90 10...  Training\n",
      "1        6  88 74 19 4 5 5 3 12 8 21 15 21 15 18 24 29 32 ...  Training\n",
      "2        6  9 2 4 7 1 1 1 0 7 29 49 76 115 141 156 169 177...  Training\n",
      "3        6  104 106 108 104 95 50 60 61 58 83 126 133 139 ...  Training\n",
      "4        6  68 72 67 67 6 2 1 1 1 1 1 14 24 24 38 65 79 94...  Training\n",
      "test\n",
      "6\n",
      "img shape:  2304\n",
      "size: 48 x 48\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGfCAYAAAAZGgYhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/PklEQVR4nO3dfXCV1Z0H8G8CJLwlNySQhAhBbEFQCypvZrG7LaZlmNbFlenajp1lu04dWbAC7rRmp2rrtMbV2UptI1aXgp0tmy07gy3uCOtgxWkXUKKOKF1EZZcoJLxIXoGAybN/ONwx3N833h888dxcv5+ZzNSTw3PP83ZP732++Z2cKIoiiIiIfMJyQw9AREQ+nTQBiYhIEJqAREQkCE1AIiIShCYgEREJQhOQiIgEoQlIRESC0AQkIiJBaAISEZEgNAGJiEgQg/trw3V1dXjooYfQ1NSE6dOn42c/+xlmz579sf+up6cHBw8eREFBAXJycvpreCIi0k+iKEJ7ezsqKiqQm9vH55yoH9TX10d5eXnRL3/5y+iNN96Ivv3tb0dFRUVRc3Pzx/7bxsbGCIB+9KMf/ehngP80Njb2+X6fE0XxFyOdM2cOZs2ahZ///OcAPvxUM378eNx+++246667+vy3ra2tKCoqwrhx41JmzkGDBpn/xtqF7u5us++pU6fM9g8++MBsP3PmTErb6dOnzb49PT1pj8/bPz8/3+zLjgnbttU+bNgws29paanZXlJSYrYXFhaa7SNGjEhpGzp0qNnXu5+DB9sf4q3+Q4YMiWXb1idz9mmd/b+/OF6TnWPrmgX4NX7y5MmUts7OTrPviRMnzHZ2v7H+x48fT2k7duyY2be9vd1st8YN2PvPxsfuTdafHUPrXLBrgl3j7D5k14p1jtj7G1NQUGC2jxw5Mu1tWOc4iiK0traipaUFiUSC/tvYv4I7ffo0GhoaUFNTk2zLzc1FdXU1tm/fntK/q6sLXV1dyf8+e7Hl5uam3LzsZrYuInZhsW2wi8XzZuP9ytDT3/uaceyP902SvcFb7Xl5eWZf1u4di9UeYgJi2+7PCYhtm01M1na8kxh7w2bbsfaTjZvds557Oa57M8Q9G2I/+/zazPGaHzee2EMIR48eRXd3N8rKynq1l5WVoampKaV/bW0tEolE8mf8+PFxD0lERDJQ8BRcTU0NWltbkz+NjY2hhyQiIp+A2L+CGz16NAYNGoTm5uZe7c3NzSgvL0/pn5+fb34nan0Fx75Wsz7meZ+NsG17vt5jvF8heF6TfcXB9t96HlNcXGz2HT16tNk+atQos519b2y1e57d9MXzFYL3eYxnLGzbbD/j+CrYe6wY6+sz9pyCYc8e2LM+9rzQ4t1P62vCj37N/1Ge+x7wXW/ee5b1Z18dW2Nh15v3q1PreA0fPtzsaz0r7u7uRktLi9n/o2L/BJSXl4cZM2Zg69atybaenh5s3boVVVVVcb+ciIgMUP3yd0ArV67E4sWLMXPmTMyePRurVq1CZ2cnvvWtb/XHy4mIyADULxPQTTfdhCNHjuCee+5BU1MTrrzySmzevDklmCAiIp9e/VYJYdmyZVi2bFl/bV5ERAa44Ck4ERH5dOq3T0AXKicnJyXl4Umfef6Qqq9tx/Ga3j88s17TU9kA4H/Qaf3lM0vBsb9gZmk3K2EH2Ikqzx9c9sWTYPP+oWMcf8zr5UlZef/4lfW3riF2XXn/CNnzB8cseecZN2Anu7x/KMv6M54UHBs3q7DCeP7Ymh1DTwqOJRqt+z7d46dPQCIiEoQmIBERCUITkIiIBKEJSEREghhQIYS++qaLPaBlDwCtB4neki7soSPjeaDJHjqyshlWsICFB9gDZPawmI3FeiAZV6XtOCoFx9Vu8S4D4AlKeEvUsNe0zrOnL+BfYsB6yO25foB4AkJsuQhWuoeFFqxrgr2mdxkNz/XG7h92fjxLWrBjYr13KoQgIiIZTROQiIgEoQlIRESC0AQkIiJBaAISEZEgMjYFZ/GkQbyldTzJNm9ZC+/ia1ZKho27qKjIbGfldayFwFiJDW9pFM8iXv2ZdmO8i8Z5eJORnsUIAXtBMe81zhYls643b6LTmxi0jjkr8eRNwXnK6LBrny2w19nZabZbx4Udb3bu2bXP0mfWsWUpRbafrL+VgmPHu729PaUt3eSvPgGJiEgQmoBERCQITUAiIhKEJiAREQlCE5CIiASRsSm4Dz74IO1F5azEjjchFMeCdCxR4k2NWe0sIcQWjbMWngPspA1L37AkC0v3sOSUlcDx1sPypsmslFVci8Z5FoeLK43pqQ/oSSP21e7h3bbnnmUJLlZnzrr2WaqNYWNh16dVU86b3PReE1bajyXmGHYMrbGw+76joyOlTSk4ERHJaJqAREQkCE1AIiIShCYgEREJQhOQiIgEkbEpOCtF4a3Blu52+2q3xLUiqmeVU5Z2Y+k4lm6xknreumRsfzw1uzznDPAntTzXj3fb1v54txFHrTVvmoodc6ud9fXUk+ur3do+68uuT5aOs+4JloLzXvvsuFjpuDiOCcBXN7bOhTe5ylJ91vsEu97a2tpS2tJND+sTkIiIBKEJSEREgtAEJCIiQWgCEhGRIDI2hGDxlMWJI2wA2A8p2YNLb3kZthDaiBEjUtqsheRYX4CXBfIsvuYpCwPw83P69Om0x5Fu+aWPe03PA9o4StrEdaw84QwWZGDYdehZ7I5tg/E8FPcGOdg1bt0TbNveBRDZdWvtJ1u8jh1DdqzYPe4pl+O5NwH7/YaNzyrFoxCCiIhkNE1AIiIShCYgEREJQhOQiIgEoQlIRESCyNgUXG5ubkoSxZM+Y6kXtg2Whkn39QA7DdLXa7JyOVYpEVaOIz8/32xn+2Mlp7wlXVjShrG2w9JEcZTFYdh5Y0kgzwJhcaX6WLLNc1y8SU/P63nLYXnL63iwsbB7wrMNdh7YNWGdf3YPehOGTU1NZvtFF12U0jZmzBizL7tnT548mXZ/VvrosssuS2nr7u5GQ0OD2f+j9AlIRESC0AQkIiJBaAISEZEgNAGJiEgQmoBERCSIjE3BeXgSNSzdwtqtdM+JEyfMvp4F5gCegrMSb2zhOZb48RwTT2Kur/7sNeNIcLEUj6cGWxw131h/77bjEFfS09qOt+ZbHKk2htV8Y6xjzvadbZvtD0v7WQlYT+09gJ9Pz4J0bOE9lmArKChIe9tsGyUlJSlt6V4/+gQkIiJBaAISEZEgNAGJiEgQmoBERCQITUAiIhKEOwX3wgsv4KGHHkJDQwMOHTqEjRs34oYbbkj+Pooi3HvvvXjiiSfQ0tKCuXPnYvXq1Zg0aZLrdaIoSkmzeOpKxZXg8iSevK/JEmxWOs5b882TSGN1zLztbP89q8p602SelW+9q5Z62r319BhP/7hWj/Vc4wzbf88KvIy3Pp41dnadeMfnScGxtBvbBmtn58Kq4+a9fxKJhNluvd946mWmy/0JqLOzE9OnT0ddXZ35+wcffBCPPPIIHnvsMezcuRMjRozA/PnzaTxQREQ+ndz/92TBggVYsGCB+bsoirBq1Sp8//vfx8KFCwEAv/rVr1BWVoannnoKX//611P+TVdXF7q6upL/3dbW5h2SiIgMQLE+A9q/fz+amppQXV2dbEskEpgzZw62b99u/pva2lokEonkz/jx4+MckoiIZKhYJ6Cz61aUlZX1ai8rK6NrWtTU1KC1tTX509jYGOeQREQkQwUvxZOfn+9aQEpERLJDrBNQeXk5AKC5uRljx45Ntjc3N+PKK690bcuTYrJ4Uzme9Ih3FUXWzsZi1afyJrU8r+kdH0vDeFY59a58ylJMnu2wY+VNQvVnCs6bkLJ46hoCvtSY97x5r1uLNwVntcd1HkaMGGG2jxo1KqWNrbTrTccdP37cbLfuQ+8qxqwepbWf7JxZz+3TXTU51q/gJk6ciPLycmzdujXZ1tbWhp07d6KqqirOlxIRkQHO/Qmoo6MDb731VvK/9+/fj1dffRXFxcWorKzE8uXL8aMf/QiTJk3CxIkTcffdd6OioqLX3wqJiIi4J6Bdu3bhi1/8YvK/V65cCQBYvHgx1q1bh+9+97vo7OzErbfeipaWFlx77bXYvHkzLeUtIiKfTu4J6Atf+EKf36fm5OTgvvvuw3333XdBAxMRkewWPAXH5OTkpP3A03pgyh7osW2yB4ZWuQvWN64SPay/p6+nPa6SO55xexZHA3xlmFh/bwjBsz9ebH885Yy8QQG2+Jp13XoXpGM8x9Z7TDyBCPZ+EFc5I2s/WbqXtX/0D/I/in17ZO0/O4Zs20eOHDHbrRABWxjPOobphmZUjFRERILQBCQiIkFoAhIRkSA0AYmISBCagEREJIiMTcFZPOVOvCk4b3kMC0vUsPQRa7dSP3GV+bH237N43fn09/CWTIlj0Thvu2eM3rJNjJVu8h4rT5KQlWjxnmM2Rs916EkGMt5txHHeWPKMtXveawA7jetNRrL3PSv960nzKgUnIiIZTROQiIgEoQlIRESC0AQkIiJBaAISEZEgBlQKzrNoHEuDeBdsYtuxeBaY66vdW5+qv7Bj5U0YxlHHjGFjtF7TUzfOO5a40nue7cdVx8ziTY2xY+i9Dy3elKLFW+/PWx/Ruifa29vNvh0dHWb7qVOnXK9p1evzpA4Bfn6shJ2VjAPsfVcKTkREMpomIBERCUITkIiIBKEJSEREgtAEJCIiQWRsCi6KorSTMlY/9m/ZSo9slVMrHceSQGyVzzhWPvUm0hjrNdkxiSvx5FmF1VuDy5PI8yayPIki1te7kitjvaZ3pVBP0pMdV9bu3X+rv7f2nqd2nLeWondVWWvVUraCKFvhlI2FHUPrfLL3MYa9N1nvCeyYWNdEuulhfQISEZEgNAGJiEgQmoBERCQITUAiIhJEVoQQLOwBZWdnp9nOymBYY2AP7kaOHGm2s/6eh9/s4WIcJVPYw2kWFGA8QQn2MNsbNmD94yj1wl7TOi7eUIE3EOFZkI49KPeUrmHBFHatxMG7OJznHMcVEGLH1gocsPcD1t7W1ubq73n4H0d4hF0TVrtCCCIiktE0AYmISBCagEREJAhNQCIiEoQmIBERCSJjU3C5ublpJ4sKCwtT2lhy5NixY65xeMqusNIb+fn5ZrtnkSyWymGpPk9pIZZYYcfQu5/W2D1lVPpqZ9uxjq13UTJ2nq1j61mMr69tM55yOSyp5ll8zVMmCuAJKU96MY6SO4C9P96SVZ6yUuw1CwoKzL5sYbcTJ0642q2SPt5yPp5kmyctqxSciIhkNE1AIiIShCYgEREJQhOQiIgEoQlIRESCyNgUXE5OTkqyiKWYrDQIS6D09XoW6zVZPahhw4aZ7azeFEuKWMk2tg2WTPEkpFhijqV14kglsUW5WMKOtbPXtBJ5LKV3ITUHz/LUWTuf17TOJzv3noX0APt8sr7sWmFJLVZj0dof77jZ+wG7Py3sfYIlQD2LybFxJBIJs72rq8tsZ0lX6/3Dex0ynvqN1nWY7vWtT0AiIhKEJiAREQlCE5CIiAShCUhERILQBCQiIkFkbArO4lmhs7293Wz3po+sJEtRUZHZl6WsWBqGJYqslRHZvlt18ABgxIgRZruVeGIpm/fffz/t8QE8NWclc1gSiB1b1u5J07HUmHe1TOtceNNHLEnIxmi1s9QUw7Zt1f1i22bnnt1vHR0dZruVjvOuKsvuCc+KtWPHjjXbS0tLzXbPdciuH5boLCkpMdtZvTbrGLLUIcOOi/Vext6vrHal4EREJKNpAhIRkSA0AYmISBCagEREJAjXBFRbW4tZs2ahoKAApaWluOGGG7B3795efU6dOoWlS5eipKQEI0eOxKJFi9Dc3BzroEVEZOBzpeC2bduGpUuXYtasWfjggw/wj//4j/jyl7+MPXv2JFNXK1aswH/+539iw4YNSCQSWLZsGW688Ub88Y9/dA2sq6srJaHBUiVW+oqleFg6g9UUs17TUw8K8NeysupQsdpULO3GkndW6oUle8rKysx2z2qrgJ3iYYk5lqbav3+/2c4SRaNHj05pY8k7dj7ZMbfOpzcF511x1Kq1xlKKrMZgS0uL2X78+PG0+7Lzw643dn1ax5YlOlk7O28erL6Zd//HjBmT0sauN/Y+xo6VdS0D9nljiVZvXUcLe7/y1PVL2Wbarw5g8+bNvf573bp1KC0tRUNDA/78z/8cra2tWLNmDdavX4958+YBANauXYupU6dix44duOaaazwvJyIiWeyCngG1trYCAIqLiwEADQ0NOHPmDKqrq5N9pkyZgsrKSmzfvt3cRldXF9ra2nr9iIhI9jvvCainpwfLly/H3LlzccUVVwAAmpqakJeXl/KVTllZGZqamszt1NbWIpFIJH/Gjx9/vkMSEZEB5LwnoKVLl+L1119HfX39BQ2gpqYGra2tyZ/GxsYL2p6IiAwM51WKZ9myZXj66afxwgsvYNy4ccn28vJynD59Gi0tLb0+BTU3N6O8vNzcVn5+vln2ITc3N+0HZFbggC2QxR7QMtYDQ/Zwmj2IZQ/v2MNI64E268se9rGvMq2HlKyEkHeBPbafnjIy7PywY87GYj0Y9V4TbNvWdcn2nZ0f9ppsjOwhsgcLbFjiWkyNsY6hNzzB9scKLbDQh7f8D9uOFcxhgQUWnvAudGmFE1jpI9bOztuFBAs8fV1HP4oiLFu2DBs3bsRzzz2HiRMn9vr9jBkzMGTIEGzdujXZtnfvXhw4cABVVVWelxIRkSzn+gS0dOlSrF+/Hr/97W9RUFCQfK6TSCQwbNgwJBIJ3HLLLVi5ciWKi4tRWFiI22+/HVVVVUrAiYhIL64JaPXq1QCAL3zhC73a165di7/9278FADz88MPIzc3FokWL0NXVhfnz5+PRRx+NZbAiIpI9XBNQOt/rDR06FHV1dairqzvvQYmISPZTLTgREQkiYxeksxIxrNSLhZWLYSVTWLuVEPMujsYSUuw1PfvJUlMs9WKVb2HpI2+qz7PIGhu3d+E9dgytFA8ru+JNqnnG4U1ZeV6TpfRYsokdW+saZ8eKJc9Y6tJzHbIyMmzc7B73YOVvvPeyVW7KW4LLs7giYKfg2Hk4cuSI2c6uFeueZfeJZ6HQc+kTkIiIBKEJSEREgtAEJCIiQWgCEhGRIDQBiYhIEBmbgjtz5kxKisSTtmBJMpZK8iSEWF0ytg2WJmOJJ2vsLJXkTR9Z22Z1xg4ePGi2s/5sjFb9LJb4YbXGWL06z8JubBvsvLFtW/1ZIo2de4YdF086jtUgY4kn61ph22CpMbZtdn1a9d3Y8WYLsnlSpCwxxxZd9C4YaPHWUmSvydpHjRqV0lZaWmr2ZatSs2NonX/Pe2q616s+AYmISBCagEREJAhNQCIiEoQmIBERCUITkIiIBJGxKbghQ4akpCs8qReWyGLbYGklK4HCEjUs9eJN1Fj9WfLs1KlTZjvrb6WsbrjhBrPvK6+8Yra/9tprZvvx48fNdk8qidWbYgk2VpfPqjXHjgk7bx4sXelN3jFWqogdQ5ZAiiOlyO6fY8eOme3smHvqmLFrnO2nNUZWT621tdVsZzwJWM/4AH4NeVbmZSlSliRk9fes1/Ss7NzT02PW+zuXPgGJiEgQmoBERCQITUAiIhKEJiAREQlCE5CIiASRsSm4nJyclLQIS0hZWKKEpd1Y6sdKMXlXuWQ8qReWVmEJO5bsspIsjY2NZl+WHKqsrDTbWbrHqhM2ceJEs68n1QbYK2sC9nljKR6W1PLUX/PUjeurP7smrLGwdBhLx7Fr3Lre2Pg+85nPpL0NADh06JDZbt3LbBsXX3yx2c6uT2v1T7Y/7ByzY8veP6x0HLsHPeehr9e07jd2/5SXl5vthw8fNtutxCQ7VqoFJyIiA44mIBERCUITkIiIBKEJSEREgsjYEEIURSkPKtmDLeuBpvchLyuZ4nlAy7btDS1Yr8keRHrCBoD94PK9995zbZstSlZcXGy2Ww/Fx4wZY/ZlpU7YMT9z5ozZbh0vFmJh22Cla6zteK5NgC/u5dkO2zY79wUFBWa7p9wUO8cVFRVpbxuwgyksVGAtvAbwe8Iau3exN3Ydsof8VqkbVhbHG0LwvK+we7OkpMRsZ/vpKf3kCYedS5+AREQkCE1AIiIShCYgEREJQhOQiIgEoQlIRESCyIoUnMVbAoX1t9q9C0exbbP0iJVUY4katm1WSsRKX7FxsPI3DEvaWK9ppaAAvj8sNceOeUdHR0pbe3u72ZeVEGIpOM8CiCzt5m23xshSYCypVVhYaLZbaUe2P2wBN3YeWDrOOs+sJFJLS4vZbp1jwN4fdv+wY8KOIUvksXYP9r7CUpoWdv+wdBxLHlrvH577JN3krz4BiYhIEJqAREQkCE1AIiIShCYgEREJQhOQiIgEkbEpuO7u7pR0VhxJNZYyYokiK93D0iCMt3acNUaWMmLtrG6TJwXnrZ/lqXvGzgPDUn0sIeXZT1YHkPGk4Ni1wq5llniyrhXPQmUAP+YsHejBrgnPWNgxZOeHJbusmncs7cWSmywFx7bDzqfF+/7B0r9WuydZ29e2LWwfrdp26d7f+gQkIiJBaAISEZEgNAGJiEgQmoBERCQITUAiIhJExqbgcnJyUpIbnpX3WMLMs1JoXFjShCXY2EqkFpaaYik4q7+n1lRfvPXNLOy8sfPDjpWVqGLnwbtirdXfmxhkx5wdK+t8smPCrivGOlbelVy995vVzlJ9DOtvrfLJar6xVBtbtdST9mPHkKX9WDurm+jZBhsLu3+sunxsHJ5E47n0CUhERILQBCQiIkFoAhIRkSA0AYmISBCuEMLq1auxevVq/O///i8A4PLLL8c999yDBQsWAPiwXMqdd96J+vp6dHV1Yf78+Xj00UdRVlbmHlhubm7Kg804yknEUUrD+3DRG3xgDzotbN/j2B+2bfYAPY6Fs9gDdG84wXpo7y3/w1jnJ47yRAAPj1jngu07a2djieNaiSPI4V3Q0VOixyrP09e2vYsUevqyc8/uH1aGyvM+wcbCwhZWwION2xMOO5frqhk3bhweeOABNDQ0YNeuXZg3bx4WLlyIN954AwCwYsUKbNq0CRs2bMC2bdtw8OBB3Hjjjec9OBERyV6uT0DXX399r//+8Y9/jNWrV2PHjh0YN24c1qxZg/Xr12PevHkAgLVr12Lq1KnYsWMHrrnmmvhGLSIiA955PwPq7u5GfX09Ojs7UVVVhYaGBpw5cwbV1dXJPlOmTEFlZSW2b99Ot9PV1YW2trZePyIikv3cE9Du3bsxcuRI5Ofn47bbbsPGjRtx2WWXoampCXl5eSllzMvKytDU1ES3V1tbi0QikfwZP368eydERGTgcU9Al156KV599VXs3LkTS5YsweLFi7Fnz57zHkBNTQ1aW1uTP42Njee9LRERGTjcpXjy8vLw2c9+FgAwY8YMvPTSS/jpT3+Km266CadPn0ZLS0uvT0HNzc0oLy+n28vPzzfTLIMGDUpJynjSFqwvW8TKkxzypsNY0saTkmH7w1JTnrSON03lZZX78JY6YcecJYTiWASPHUMrwcVSYGwb7FrxllLx8Cw8yMrcsHZv4svq702FehZpZPseV7t1fXqTjp4EJBuL955l703WMWepQ6vvJ7YgXU9PD7q6ujBjxgwMGTIEW7duTf5u7969OHDgAKqqqi70ZUREJMu4PgHV1NRgwYIFqKysRHt7O9avX4/nn38eW7ZsQSKRwC233IKVK1eiuLgYhYWFuP3221FVVaUEnIiIpHBNQIcPH8bf/M3f4NChQ0gkEpg2bRq2bNmCL33pSwCAhx9+GLm5uVi0aFGvP0QVERE5l2sCWrNmTZ+/Hzp0KOrq6lBXV3dBgxIRkeynWnAiIhJExi5IZ9WC8yRQWMqos7PTbGfpHivhwdIqntpMAE+3WO3e2mksZWbxJrVYGiauBd/i2IZ1rXiSgX2xzj+7Jtj58aaVrLGzpJE31eg5tt70Ijvm1vHyXuOexKS3Vp93kUbrNeNKQLLzY72m5z0F4O971jFnx9Ba7C/d46dPQCIiEoQmIBERCUITkIiIBKEJSEREgtAEJCIiQWRsCi6KopSEimflU5bYYMkhTwoujpVZ+xJHWstTP4odK5a+8dYli+O4sLGw5JQ1RjZudu7Z6rnnVnwH7CQQ4FtxEuDn3mpnfdnxZmOxUo2eGmEAT6p5asp5X9OT9mtvb7/gbfTFc896k2oe3tWa2X6WlJSk3deTFD6XPgGJiEgQmoBERCQITUAiIhKEJiAREQlCE5CIiASRsSk4D88Kld6kiZX8YNv2rujorR1n8SahrP5x1SvzHFt2DL0131iq0apFxcbH0lfWSq6AnY5jiTlvOoylh7q6ulLa2GqwLAnFzqe1/6zeH+PZNtu+977y1HGzjl9f2LjZWKzX9NafiyMF511Rl12f1srR7PxY12y67x36BCQiIkFoAhIRkSA0AYmISBCagEREJIiMDSHk5OSkPMjyluTw8JRAYbwLfrF2az+9C3552tkDSvYg1rs/1nHxLjLGFrjq6Ogw260H9HGVl7Gw4822wR7yexYIY33ZsWKBDevht/fBP9t/7yJzcbwm20/Pttkx9LzXeMMGcYQQvNtgQRvrnvCGRNKhT0AiIhKEJiAREQlCE5CIiAShCUhERILQBCQiIkFkbArugw8+SEldeFIYnlI0fW3bSol4y994Fofrq93iTQZ6FthjSSWWbGLiWNTv5MmTZntLS4vZbo2dJX48iSzATll5FxH0pqysUj/sPLAU2Pvvv2+2d3Z2prSVlpaafb2lhRi2/56+rN26hlgpHnYM47jGvdcEO4aeZJs3eedZdJJdmwUFBSlt6V4P+gQkIiJBaAISEZEgNAGJiEgQmoBERCQITUAiIhJExqbgcnNz016czEpsxLWwmbXYEus7dOhQs50lUNjiY57Ui7cOk9U/rppVngW42Gu2tbWZ7U1NTWY7SytZKRx2TbC00okTJ9Luz/qya4Jh15bVzvp601TW2Nlid0wcCwx671nGusa9dQ29PNvxpl/jSMF5+1uJUXaNHzhwIKUt3ZSjPgGJiEgQmoBERCQITUAiIhKEJiAREQlCE5CIiASRsSk4a0VUltiwUi/e1Uk9CRTPSqbebbN2ltTypuCssXvrybFxs/6eMbL0VXt7u9lu1Uhj7SwJxfaH1Q+z0mds3FadNSCeY+Wt4cfScdZ+stp7cYyb9WfXIcPuQ+t8ercdR5osrlVl4+BNgFrYNXHw4MGUtnRXpdUnIBERCUITkIiIBKEJSEREgtAEJCIiQWRsCMF6kOh5AMoeOnoeXDLeEIL3AW1/ssaSn5+fdl/AX0rEU/7HW9KFPXC3SuCw12QPV9n5tB7ms22zkiTeB85WgIKV+WHnjZ1nT6jC+zCfsc6nd7HIOHjueyCeBdwy6f2AXZ+tra1ptQH2tZLu9a1PQCIiEoQmIBERCUITkIiIBKEJSEREgtAEJCIiQVxQCu6BBx5ATU0N7rjjDqxatQrAh4mIO++8E/X19ejq6sL8+fPx6KOPoqyszLVtTykeC0ureBMo1mt6kzPe1/Rsn5WX8aSV2OuxhBnbNku+WMfQm3iyFsgC+CJZFlbO57333jPby8vL024vKioy+7Jj+84775jtR48eNdutpFoikTD7XnnllWZ7R0eH2W6V4mH7w65ltrgiY11b3vI3jHXMWaqP7Y83RWv1Z9v2JiDZNeRJB7Lz09jYaLZb1wq7fqz2fk/BvfTSS/jFL36BadOm9WpfsWIFNm3ahA0bNmDbtm04ePAgbrzxxvN9GRERyVLnNQF1dHTg5ptvxhNPPIFRo0Yl21tbW7FmzRr85Cc/wbx58zBjxgysXbsW//3f/40dO3bENmgRERn4zmsCWrp0Kb7yla+gurq6V3tDQwPOnDnTq33KlCmorKzE9u3bzW11dXWhra2t14+IiGQ/9zOg+vp6vPzyy3jppZdSftfU1IS8vLyU74/LysrQ1NRkbq+2thY//OEPvcMQEZEBzvUJqLGxEXfccQd+/etf0zIgXjU1NWhtbU3+sIdiIiKSXVyfgBoaGnD48GFcffXVybbu7m688MIL+PnPf44tW7bg9OnTaGlp6fUpqLm5mSaK8vPzzRpVgwcPTjvlYaVNPIkswLcoGUuDjBw5kg3R5Kl7xsaX7sJPH/eaFu+x8qT9WHqPLTBXXFxstrMF3zyLkrE0GRuLtW2WxmNJwtGjR7v6W/vpTTYVFBSY7aWlpSltbN+9STW2P9a1wq6r/lwcztvOxmKdC8+Ck33x1E30LkbI3j+s/WcfOqx7Od33JdcEdN1112H37t292r71rW9hypQp+N73vofx48djyJAh2Lp1KxYtWgQA2Lt3Lw4cOICqqirPS4mISJZzTUAFBQW44oorerWNGDECJSUlyfZbbrkFK1euRHFxMQoLC3H77bejqqoK11xzTXyjFhGRAS/25Rgefvhh5ObmYtGiRb3+EFVEROSjLngCev7553v999ChQ1FXV4e6uroL3bSIiGQx1YITEZEgMnZFVKsWHEsxWamS/kzBsZUBWVKLYYk0lhDrL3GldTyJItbXs8IpwM+ndd5Ysosdb5Zq9NQxYytOsuSdp+YdS2MyhYWFZrtV943dayx55629+EmvIBrXKqSe/fG+B8VRp5Jtg13jnjqQ7N607rV0a1HqE5CIiAShCUhERILQBCQiIkFoAhIRkSA0AYmISBAZm4K7UN6kCUvxWEkWtroiq3/EEijsNT11zLwrosZRg8ubJPSk+rzJIU+tMXZMWJ0sT2rOW6uPXYdsLNZ+slVL2fFm/a3knfc8eFbgZdv3XuOebXuTnnHUjmPXpve+Yu3WfnrHzVKanmNupeDSrQWnT0AiIhKEJiAREQlCE5CIiAShCUhERILI2BDCoEGDUh7Sex6WswearJ0FAjwLvrEyKtaCe329Jnt4afE+dLQeLnoCC31hD649i+B5z5snVOJ9mB3HAlwssMKuCc8xZ33ZtlnAwYNdm3GcN+8icN5SUZ5tex78A77Qi/e+8gRt2LatoEBf2tra0t72hZQO0ycgEREJQhOQiIgEoQlIRESC0AQkIiJBaAISEZEgMjYFZ2FpC6ud9WULannKyLB0lDcl4imj400fefqzxI8X239PWslbLodt2zrPLMHEeFJZ3kQW2x/WbqX6WLrQ2x7H+Wf7z17TOs/s/HjPm7Vtb8mdOHjSn+ezHev9g6Xdjh49arYfP37cbLeOIXvfu5D3FH0CEhGRIDQBiYhIEJqAREQkCE1AIiIShCYgEREJImNTcLm5uSnpD5YaY7WvLCwNw7ZhtbOkEqv7xdIjnpQMS5V4E0+WuJJAcaV+PDx1wli9NpYcYukrK2HoSSqx8fX1mp4UHBNH7TTGW68tjkXjPLXWvDUgvXXp4uCt62hdh52dnWbf999/32xn12cikUhp87zvpXtt6hOQiIgEoQlIRESC0AQkIiJBaAISEZEgNAGJiEgQGZ2COze5whIbVqLGs5IpAIwaNcpsHzFiREobS7u1traa7cOHDzfbWfLO2h9vnTmW1rG2wxIr3vpecawqy1JgrIYfS7CdOXMmpY2dt46ODrPdWhUSsM/nyJEj0+4LAO3t7WY7O29WAomtwOs9P1ZCjKXGvDzpOM/4+upvvSa7f7yrlrJr2RqLN13qTbpax5DdD+zaHz16tNl+0UUXpbSx95rDhw+ntFn3n0WfgEREJAhNQCIiEoQmIBERCUITkIiIBJGxIYTBgwen/SDUehjHHphNnjzZbC8pKTHbrdIWzc3NZl/2MJs96PM8APUuJuZZxIuNw/uA1vPQlT3MZQ/+2TFnD1c9++8NclhjZOP28hxb7/lh/a0ABQvlsOCMd8HEOEraxHGNexe7827f85rpPrg/68iRI2m19bVt9r4yZsyYlLZJkyaZfa2g1okTJ/D000+b/Xu9/sf2EBER6QeagEREJAhNQCIiEoQmIBERCUITkIiIBJGxKTgLK8dipeBYaZSKigqznaV7rJQV68uSUCypxfbHSqawsjjekkNW+oglkrzpODZGaz/ZAllHjx4121l/dmw9KSvvsbXaPX0BnlRji37FsQieZwE7tg12X1188cVme3FxsdluXUOe8lFAPAs6xpWCs7bPzr03Acjeb44fP57SxtKi7Bpni2VaZcXY8b788stT2lgiOGWbafUSERGJmSYgEREJQhOQiIgEoQlIRESC0AQkIiJBuFJwP/jBD/DDH/6wV9ull16K//mf/wHwYSLpzjvvRH19Pbq6ujB//nw8+uijKCsrcw/sgw8+SEmLsMSTlRxitaxYuoclVjyLw7GkCUt2sTSZdbxYAsVbl81q96ZyPIuMebfBjglbfI2lmOJIqjHWufAuAsewmmrWNc6ON2v3XBPebbNEp6cGmXdBNsazPwwbi+deiaPeHeBbSJElcdn+s21b71lsEcUL4f4EdPnll+PQoUPJnz/84Q/J361YsQKbNm3Chg0bsG3bNhw8eBA33nhjrAMWEZHs4P47oMGDB6O8vDylvbW1FWvWrMH69esxb948AMDatWsxdepU7NixA9dcc425va6url7LyMZVVVhERDKb+xPQvn37UFFRgUsuuQQ333wzDhw4AABoaGjAmTNnUF1dnew7ZcoUVFZWYvv27XR7tbW1SCQSyZ/x48efx26IiMhA45qA5syZg3Xr1mHz5s1YvXo19u/fj89//vNob29HU1MT8vLyUFRU1OvflJWVoampiW6zpqYGra2tyZ/Gxsbz2hERERlYXF/BLViwIPm/p02bhjlz5mDChAn4zW9+Qx8Sf5z8/HxaakJERLLXBdWCKyoqwuTJk/HWW2/hS1/6Ek6fPo2WlpZen4Kam5vNZ0Yf5/Tp0ynpF5bkOPdTF8BrU7G0Dmu3UiLe1NShQ4fMdpaSGTt2bEobS+952z2JorhWs/SkFFmtMXbMjx07ZrZbCaGTJ0+afVlSi9XJ8qxOyrBjaK0uCdjnjSWY2P6whJ1nRVTvKqyM5xh6E4bWtr112eJoZ/cg2082RvYNkrVaMzv37NpnrGfxhw8fNvv+6U9/Smk7ceJEWq9zQX8H1NHRgbfffhtjx47FjBkzMGTIEGzdujX5+7179+LAgQOoqqq6kJcREZEs5PoE9A//8A+4/vrrMWHCBBw8eBD33nsvBg0ahG984xtIJBK45ZZbsHLlShQXF6OwsBC33347qqqqaAJOREQ+vVwT0LvvvotvfOMbOHbsGMaMGYNrr70WO3bswJgxYwAADz/8MHJzc7Fo0aJef4gqIiJyLtcEVF9f3+fvhw4dirq6OtTV1V3QoEREJPupFpyIiASRsSui5ubmpqRcJkyYYPadPHlyWm1nt2uxVhcE0KtKw1ksxcJSU96VHq0ECdu2t0achaWjGG8Kzkr3sOg9WxGUpRRZncGSkpKUNmuVRwA4cuSI2c5Sl1b9OXZM2P6w/qzelqeWGUvSsdVJCwoKUtrYn1Ww8xbH6p/sHLP7jV23Vjvr6020MlbizXvfs/5vv/222W6tEsxqI3rr6Vkp0jfffNPsa713snOZMi7XqERERGKiCUhERILQBCQiIkFoAhIRkSAyNoTQ3d2d8lBu0qRJZt/Zs2entFnlbACgpaXFbGelKqyHl8OHDzf7WoEFgD9EZaVUrId9s2bNSnt8AH9obT2M9C5gxngWPPM+tGYPUdlDceuYJxIJs683+GCN3bvgGePZDruu2PVphQ1Yf3ZdsXPs7W+N3Vv+hh0rqxyN9yG8N0BgtbO+rFyOd8E3a/+9YRjPeWPXW2FhYUobey88lz4BiYhIEJqAREQkCE1AIiIShCYgEREJQhOQiIgEkbEpuNGjR6ekLi655BKzr9XOkkAsacJSIlZyiiXmWBkMtjgTG4tVYsNbMsST1omLNzlk6c80GRsHK3PEEkKeUjze/WFjtFJcbHxsf1i7de2z1Bjbn/5cGNFTEqmv/hZvWSnPuNn4WPqVva+w17SOrSf9yrbB+rMUpbX4Z7oL4OkTkIiIBKEJSEREgtAEJCIiQWgCEhGRIDQBiYhIEBmbgps1a1ZKOsdKWwB2OoOlW1iajNUJ8yS4WO0wtg3W30rPsOQMS/uxVB+r52SJqzbXhY4D4OeNJY2s/qwGF9u2ZyE01pe1s3Ez1na8i/p567VZvElHz4KJ/ZnQ9Kb6vNuxsPub3cvp1k87y7MInvf+sc4FS8FZC4V2dnaafc+lT0AiIhKEJiAREQlCE5CIiAShCUhERILQBCQiIkFkbAruL//yLzFixIhebcXFxWZfKw3C6qxNnjzZbGdpkHfffTelja2qysbnXRnRSsm89957Zl+WbGLtFjY+b50sD08CEPDXsrLaWS00hqXJPKtFsvF5k3dWe1wJOysJFtcquZ7tsG3HUQsurhppbIzWPcvub++qv+w8W9enN3nnGYu18ikAVFRUpLR1dHSYfVNeJ61eIiIiMdMEJCIiQWgCEhGRIDQBiYhIEJqAREQkiIxNwV100UUptYc8KwyydIe3ZteoUaNS2iZOnGj2ZVgCh9VLam1tTWlra2sz+x47dsxsZ/tzbrIQ8NXr6qu/h7cWHOvvSWWxvp6ab6y/d+VPb5rMup6917inhl8cq4329ZqehCV7TU86znvNepN31gqgLOnI0nEswcZ4koTs+iwtLTXbL7300pS2qVOnmn0rKytT2tj71bn0CUhERILQBCQiIkFoAhIRkSA0AYmISBAZG0IoKipKKf3ASuBYDwy9CzOxsisjR45MaSsrKzP7slABe7jIHtRZC42x0hasnS1UZ/GW82EPuT0P3Ps7+OB9WO5hPdD1lm7xlj+yrltveRnGGgvbH295Gc958G7DE2RgfVmowBsU8Jwf9h7E2uNY1I8tXjhz5kyzfdq0aSltkyZNMvtai3mmG7LRJyAREQlCE5CIiAShCUhERILQBCQiIkFoAhIRkSAyNgU3fPjwlCSXZ7El7wJMLNllLWI2bNgws+/o0aPN9hMnTpjtrIyOlXph+97V1eVqt7DEnPdYecqAeBe785Z0YYkii3fBQGv/vak+byrLamfb8Jb5iUN/Jtg85xKwzw/bhjcFx9qtxKh33733lXXNsfQiW4xx3rx5ZvvFF1+c0jZmzBiz74XQJyAREQlCE5CIiAShCUhERILQBCQiIkG4J6D33nsP3/zmN1FSUoJhw4bhc5/7HHbt2pX8fRRFuOeeezB27FgMGzYM1dXV2LdvX6yDFhGRgc+Vgjt+/Djmzp2LL37xi3jmmWcwZswY7Nu3r9eibQ8++CAeeeQRPPnkk5g4cSLuvvtuzJ8/H3v27KFJDMvhw4dTFnliaa1za8YBPAXHkime5BCrkcbScdb4AF5/zlrcypvWYftv7SdL5bDkHUvaeBb786bGvAuEebBts/NsHS92rLz76am1FkdNPsDef5YaYzXF2Gt6kmBxLXZnHUN2flg7Gwu79q2xeJN33mSoNXardiUAXHbZZWY7W5DOulbYe4o1jnQX13NNQP/0T/+E8ePHY+3atcm2j64OGkURVq1ahe9///tYuHAhAOBXv/oVysrK8NRTT+HrX/+65+VERCSLub6C+93vfoeZM2fia1/7GkpLS3HVVVfhiSeeSP5+//79aGpqQnV1dbItkUhgzpw52L59u7nNrq4utLW19foREZHs55qA3nnnHaxevRqTJk3Cli1bsGTJEnznO9/Bk08+CQBoamoCkLpcQVlZWfJ356qtrUUikUj+jB8//nz2Q0REBhjXBNTT04Orr74a999/P6666irceuut+Pa3v43HHnvsvAdQU1OD1tbW5E9jY+N5b0tERAYO1wQ0duzYlIdZU6dOxYEDBwAA5eXlAIDm5uZefZqbm5O/O1d+fj4KCwt7/YiISPZzhRDmzp2LvXv39mp78803MWHCBAAfBhLKy8uxdetWXHnllQA+XPVz586dWLJkiWtgubm5KckaT3qEJcxYsomle6wki5VSA3gSiCVnCgoKzHZrsj5+/LjZl6Wm2LHyrNzItsH207P/7Jh4E3aMNXaWAotjP7216uJIjXnHHYd0001neVYF9dbNY9u22tmximvlXM+qst7kJrvHrfchlrxjCTb2vme9f7LzYNW6ZPUvz+WagFasWIE/+7M/w/3334+//uu/xosvvojHH38cjz/+OIAPT8Ly5cvxox/9CJMmTUrGsCsqKnDDDTd4XkpERLKcawKaNWsWNm7ciJqaGtx3332YOHEiVq1ahZtvvjnZ57vf/S46Oztx6623oqWlBddeey02b97s+hsgERHJfu7lGL761a/iq1/9Kv19Tk4O7rvvPtx3330XNDAREcluqgUnIiJBZOyCdAUFBSmJOM/DuxEjRrhej4UTrIeU7MEl+yNaVh6DLWBnlcfYvXu32Zc9FPYsbMawB5pxlHrxLtYVV7uFHRMWfGAPhT28IQRLXAvSWWNh22DXWxxBAe+4PdtmvNdyHAEPtm3vgnTWopPsfYwFntj5/Gh5tbNYKTRr3OmGhvQJSEREgtAEJCIiQWgCEhGRIDQBiYhIEJqAREQkiIxNwSUSiZQUnKfMBCuDwRJMrL+VemFJmJaWFrOdpaw6OzvNdiuxwsbNjglrtxJCbN9Z+sbbbo2FHUPvIl6eVJJ33J6yM97yRCwl5En1xZWC86TGvAu4MdZxiassjsVzfwO+xRUB36J+bD/ZttlCl9b2Wfp38uTJZntra6vZbq1KUFJSYva1rrd0z6U+AYmISBCagEREJAhNQCIiEoQmIBERCSLjQghnH6xaZW08IQSrTAUQTwiBrQfEQgVsbQy2HetBr7fUiSec4C07EkcpHk/fvvrHURqFPfz1bHsghxA8/QdqCIFtuz9DCOxYeYM27D3LE3xg6wGx96z29vaUNhaGsK6fs+/fH1cSKyfyFM36BLz77rtmAkNERAaWxsZGjBs3jv4+4yagnp4eHDx4EAUFBWhvb8f48ePR2NiY1Ut1t7W1aT+zxKdhHwHtZ7aJez+jKEJ7ezsqKir6/CYh476Cy83NTc6YZz/aFRYWZvXJP0v7mT0+DfsIaD+zTZz7mUgkPraPQggiIhKEJiAREQkioyeg/Px83HvvvcjPzw89lH6l/cwen4Z9BLSf2SbUfmZcCEFERD4dMvoTkIiIZC9NQCIiEoQmIBERCUITkIiIBKEJSEREgsjoCaiurg4XX3wxhg4dijlz5uDFF18MPaQL8sILL+D6669HRUUFcnJy8NRTT/X6fRRFuOeeezB27FgMGzYM1dXV2LdvX5jBnqfa2lrMmjULBQUFKC0txQ033IC9e/f26nPq1CksXboUJSUlGDlyJBYtWoTm5uZAIz4/q1evxrRp05J/OV5VVYVnnnkm+fts2MdzPfDAA8jJycHy5cuTbdmwnz/4wQ+Qk5PT62fKlCnJ32fDPp713nvv4Zvf/CZKSkowbNgwfO5zn8OuXbuSv/+k34MydgL693//d6xcuRL33nsvXn75ZUyfPh3z58/H4cOHQw/tvHV2dmL69Omoq6szf//ggw/ikUcewWOPPYadO3dixIgRmD9/Pq1km4m2bduGpUuXYseOHXj22Wdx5swZfPnLX+5VdXfFihXYtGkTNmzYgG3btuHgwYO48cYbA47ab9y4cXjggQfQ0NCAXbt2Yd68eVi4cCHeeOMNANmxjx/10ksv4Re/+AWmTZvWqz1b9vPyyy/HoUOHkj9/+MMfkr/Lln08fvw45s6diyFDhuCZZ57Bnj178M///M8YNWpUss8n/h4UZajZs2dHS5cuTf53d3d3VFFREdXW1gYcVXwARBs3bkz+d09PT1ReXh499NBDybaWlpYoPz8/+rd/+7cAI4zH4cOHIwDRtm3boij6cJ+GDBkSbdiwIdnnT3/6UwQg2r59e6hhxmLUqFHRv/zLv2TdPra3t0eTJk2Knn322egv/uIvojvuuCOKouw5l/fee280ffp083fZso9RFEXf+973omuvvZb+PsR7UEZ+Ajp9+jQaGhpQXV2dbMvNzUV1dTW2b98ecGT9Z//+/Whqauq1z4lEAnPmzBnQ+9za2goAKC4uBgA0NDTgzJkzvfZzypQpqKysHLD72d3djfr6enR2dqKqqirr9nHp0qX4yle+0mt/gOw6l/v27UNFRQUuueQS3HzzzThw4ACA7NrH3/3ud5g5cya+9rWvobS0FFdddRWeeOKJ5O9DvAdl5AR09OhRdHd3o6ysrFd7WVkZmpqaAo2qf53dr2za556eHixfvhxz587FFVdcAeDD/czLy0NRUVGvvgNxP3fv3o2RI0ciPz8ft912GzZu3IjLLrssq/axvr4eL7/8Mmpra1N+ly37OWfOHKxbtw6bN2/G6tWrsX//fnz+859He3t71uwjALzzzjtYvXo1Jk2ahC1btmDJkiX4zne+gyeffBJAmPegjFuOQbLH0qVL8frrr/f6Pj2bXHrppXj11VfR2tqK//iP/8DixYuxbdu20MOKTWNjI+644w48++yzGDp0aOjh9JsFCxYk//e0adMwZ84cTJgwAb/5zW/oKqADUU9PD2bOnIn7778fAHDVVVfh9ddfx2OPPYbFixcHGVNGfgIaPXo0Bg0alJI0aW5uRnl5eaBR9a+z+5Ut+7xs2TI8/fTT+P3vf99rRcTy8nKcPn0aLS0tvfoPxP3My8vDZz/7WcyYMQO1tbWYPn06fvrTn2bNPjY0NODw4cO4+uqrMXjwYAwePBjbtm3DI488gsGDB6OsrCwr9vNcRUVFmDx5Mt56662sOZcAMHbsWFx22WW92qZOnZr8ujHEe1BGTkB5eXmYMWMGtm7dmmzr6enB1q1bUVVVFXBk/WfixIkoLy/vtc9tbW3YuXPngNrnKIqwbNkybNy4Ec899xwmTpzY6/czZszAkCFDeu3n3r17ceDAgQG1n5aenh50dXVlzT5ed9112L17N1599dXkz8yZM3HzzTcn/3c27Oe5Ojo68Pbbb2Ps2LFZcy4BYO7cuSl/EvHmm29iwoQJAAK9B/VLtCEG9fX1UX5+frRu3bpoz5490a233hoVFRVFTU1NoYd23trb26NXXnkleuWVVyIA0U9+8pPolVdeif7v//4viqIoeuCBB6KioqLot7/9bfTaa69FCxcujCZOnBidPHky8MjTt2TJkiiRSETPP/98dOjQoeTPiRMnkn1uu+22qLKyMnruueeiXbt2RVVVVVFVVVXAUfvddddd0bZt26L9+/dHr732WnTXXXdFOTk50X/9139FUZQd+2j5aAouirJjP++8887o+eefj/bv3x/98Y9/jKqrq6PRo0dHhw8fjqIoO/YxiqLoxRdfjAYPHhz9+Mc/jvbt2xf9+te/joYPHx7967/+a7LPJ/0elLETUBRF0c9+9rOosrIyysvLi2bPnh3t2LEj9JAuyO9///sIQMrP4sWLoyj6MAZ59913R2VlZVF+fn503XXXRXv37g07aCdr/wBEa9euTfY5efJk9Pd///fRqFGjouHDh0d/9Vd/FR06dCjcoM/D3/3d30UTJkyI8vLyojFjxkTXXXddcvKJouzYR8u5E1A27OdNN90UjR07NsrLy4suuuii6Kabboreeuut5O+zYR/P2rRpU3TFFVdE+fn50ZQpU6LHH3+81+8/6fcgrQckIiJBZOQzIBERyX6agEREJAhNQCIiEoQmIBERCUITkIiIBKEJSEREgtAEJCIiQWgCEhGRIDQBiYhIEJqAREQkCE1AIiISxP8DShjI6+OS59wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img is gray scale:  True\n",
      "number of images:  920\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/davilsena/ckdataset\n",
    "\n",
    "# load in datasets\n",
    "# load in the ckextneded.csv file\n",
    "ckplus_csv_dataset = pd.read_csv(cwd + '/datasets/ckextended.csv')\n",
    "print(ckplus_csv_dataset.head())\n",
    "print(\"test\")\n",
    "print(ckplus_csv_dataset.iloc[0, 0])\n",
    "\n",
    "# display the first image in the dataset by getting the data in the first row of the second column\n",
    "# and reshaping it to 48x48\n",
    "img = ckplus_csv_dataset.iloc[0, 1]\n",
    "img = img.split(' ')\n",
    "img = np.array(img, dtype='float32')\n",
    "print(\"img shape: \", img.shape[0])\n",
    "size = int(np.sqrt(img.shape[0]))\n",
    "print(f\"size: {size} x {size}\")\n",
    "img = img.reshape((size, size))\n",
    "# upscale image to 64x64\n",
    "img = cv2.resize(img, (64, 64))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# check if img is grey scale\n",
    "print(\"img is gray scale: \", img.ndim == 2)\n",
    "\n",
    "# if ckplus_dataset row in the 3rd column is training, then the image is for training, else it is for testing\n",
    "# create a list of training and testing images\n",
    "ckplus_csv_images = []\n",
    "ckplus_csv_labels = []\n",
    "\n",
    "for i in range(0, ckplus_csv_dataset.shape[0]):\n",
    "    img = ckplus_csv_dataset.iloc[i, 1]\n",
    "    img = img.split(' ')\n",
    "    img = np.array(img, dtype='float32')\n",
    "    size = int(np.sqrt(img.shape[0]))\n",
    "    img = img.reshape((size, size))\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "    ckplus_csv_images.append(img)\n",
    "    ckplus_csv_labels.append(ckplus_csv_dataset.iloc[i, 0])\n",
    "\n",
    "ckplus_csv_dict = {\n",
    "    'images': ckplus_csv_images,\n",
    "    'labels': ckplus_csv_labels\n",
    "}\n",
    "\n",
    "print(\"number of images: \", len(ckplus_csv_images))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_using_viola_johns_algorithm(img, classifier = 'haarcascade_frontalface_default.xml'):\n",
    "    # load in the haar cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier(cwd +'/' +classifier)\n",
    "\n",
    "    # convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # detect the faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    # draw a rectangle around the face\n",
    "    for (x, y, w, h) in faces:\n",
    "        # crop the image\n",
    "        img = img[y:y+h, x:x+w]\n",
    "        # resize the image to 48x48\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        # return the image\n",
    "        return img\n",
    "    \n",
    "# croped_image = crop_using_viola_johns_algorithm(cv2.imread(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/images/0/Anger.jpg'))\n",
    "# test the function\n",
    "# cv2.imwrite(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/images/0/Anger_cropped.jpg', croped_image.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load YOLOv3 weights and config file\n",
    "net = cv2.dnn.readNet(cwd + '/yolov3.weights', cwd + '/yolov3.cfg')\n",
    "\n",
    "with open(cwd + '/coco.names', 'r') as f:\n",
    "    classes = f.read().strip().split('\\n')\n",
    "def alternative_face_detector(img):\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward()\n",
    "    layer_names = net.getUnconnectedOutLayersNames()\n",
    "    detections = net.forward(layer_names)\n",
    "\n",
    "    for detection in detections:\n",
    "        for obj in detection:\n",
    "            scores = obj[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            if confidence > 0.5 and classes[classID] == \"person\":\n",
    "                return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['haarcascade_frontalface_default.xml', 'haarcascade_frontalface_alt.xml', 'haarcascade_frontalface_alt2.xml', 'haarcascade_frontalface_alt_tree.xml','haarcascade_profileface.xml']\n",
    "\n",
    "if (os.listdir(cwd + \"/datasets/ckextended/images/\") and not os.listdir(cwd + \"/datasets/ckextended/cropped_images/\")):\n",
    "    for folder in os.listdir(cwd + \"/datasets/ckextended/images/\"):\n",
    "        for file in os.listdir(cwd + \"/datasets/ckextended/images/\" + folder):\n",
    "            img = cv2.imread(cwd + \"/datasets/ckextended/images/\" + folder + \"/\" + file)\n",
    "            cropped_image = crop_using_viola_johns_algorithm(img)\n",
    "            if cropped_image is None:\n",
    "                print(\"no face detected\")\n",
    "                break\n",
    "            if cropped_image is None:\n",
    "                print(\"no face detected\")\n",
    "                break\n",
    "            if alternative_face_detector(cropped_image) == False:\n",
    "                for classifier in classifiers:\n",
    "                    cropped_image = crop_using_viola_johns_algorithm(img, classifier)\n",
    "                    if cropped_image is None:\n",
    "                        break\n",
    "                    if alternative_face_detector(cropped_image) == True:\n",
    "                        break\n",
    "                \n",
    "            if cropped_image is None:\n",
    "                print(\"no face detected\")\n",
    "                break\n",
    "\n",
    "            if not os.path.exists(cwd + '/datasets/ckextended/cropped_images'):\n",
    "                os.makedirs(cwd + '/datasets/ckextended/cropped_images')\n",
    "            if not os.path.exists(cwd + '/datasets/ckextended/cropped_images/' + folder):\n",
    "                os.makedirs(cwd + '/datasets/ckextended/cropped_images/' + folder)\n",
    "            \n",
    "            cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imwrite(cwd + '/datasets/ckextended/cropped_images/' + folder + '/' + file, cropped_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_label_for_string(label):\n",
    "    anger = ['anger', 'Anger', 'angry', 'Angry']\n",
    "    disgust = ['disgust', 'Disgust', 'disgusted', 'Disgusted']\n",
    "    fear = ['fear', 'Fear', 'scared', 'Scared']\n",
    "    happy = ['happy', 'Happy','happiness', 'Happiness']\n",
    "    sad = ['sad', 'Sad','sadness', 'Sadness']\n",
    "    surprised = ['surprised', 'Surprised','surprise', 'Surprise']\n",
    "    neutral = ['neutral', 'Neutral']\n",
    "    contempt = ['contempt', 'Contempt']\n",
    "\n",
    "    if label == anger:\n",
    "        return 0\n",
    "    elif label in disgust:\n",
    "        return 1\n",
    "    elif label in fear:\n",
    "        return 2\n",
    "    elif label in happy:\n",
    "        return 3\n",
    "    elif label in sad:\n",
    "        return 4\n",
    "    elif label in surprised:\n",
    "        return 5\n",
    "    elif label in neutral:\n",
    "        return 6\n",
    "    elif label in contempt:\n",
    "        return 7\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckplus_cropped_images = []\n",
    "ckplus_cropped_labels = []\n",
    "\n",
    "for folder in os.listdir(cwd + \"/datasets/ckextended/cropped_images/\"):\n",
    "    for file in os.listdir(cwd + \"/datasets/ckextended/cropped_images/\" + folder):\n",
    "        img = cv2.imread(cwd + \"/datasets/ckextended/cropped_images/\" + folder + \"/\" + file)\n",
    "        if img is None:\n",
    "            print(\"no image\")\n",
    "            break\n",
    "        ckplus_cropped_images.append(img)\n",
    "        ckplus_cropped_labels.append(get_number_label_for_string(folder))\n",
    "\n",
    "ckplus_dict = {\n",
    "    'images': ckplus_cropped_images,\n",
    "    'labels': ckplus_cropped_labels\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Kaggle tapakah68/facial-emotion-recognition Dataset and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/tapakah68/facial-emotion-recognition\n",
    "\n",
    "# crop images if they arent' already cropped\n",
    "\n",
    "if (os.listdir(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images') == []):\n",
    "\n",
    "    classifiers = ['haarcascade_frontalface_default.xml', 'haarcascade_frontalface_alt.xml', 'haarcascade_frontalface_alt2.xml', 'haarcascade_frontalface_alt_tree.xml','haarcascade_profileface.xml']\n",
    "\n",
    "    # go through the folders in the dataset/kaggle-facial-emotional-recognition-dataset \n",
    "    for folder in os.listdir(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/images'):\n",
    "        for img_name in os.listdir(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/images/' + folder):\n",
    "            img = cv2.imread(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/images/' + folder + '/' + img_name)\n",
    "            cropped_image = crop_using_viola_johns_algorithm(img)\n",
    "            if cropped_image is None:\n",
    "                print(\"no face detected\")\n",
    "                break\n",
    "            if cropped_image is None:\n",
    "                print(\"no face detected\")\n",
    "                break\n",
    "            if alternative_face_detector(cropped_image) == False:\n",
    "                for classifier in classifiers:\n",
    "                    cropped_image = crop_using_viola_johns_algorithm(img, classifier)\n",
    "                    if cropped_image is None:\n",
    "                        break\n",
    "                    if alternative_face_detector(cropped_image) == True:\n",
    "                        break\n",
    "                \n",
    "            if cropped_image is None:\n",
    "                print(\"no face detected\")\n",
    "                break\n",
    "            \n",
    "\n",
    "            # save the image\n",
    "            # if folder doesn't exist, create it\n",
    "            if not os.path.exists(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images'):\n",
    "                os.makedirs(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images')\n",
    "            if not os.path.exists(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images/' + folder):\n",
    "                os.makedirs(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images/' + folder)\n",
    "            \n",
    "\n",
    "                    # convert the image to grayscale\n",
    "            \n",
    "            cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imwrite(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images/' + folder + '/' + img_name, cropped_image)\n",
    "        # go through the images in the folder\n",
    "    \n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle images:  125\n",
      "kaggle labels:  125\n"
     ]
    }
   ],
   "source": [
    "# load in the cropped images\n",
    "# create a list of training and testing images\n",
    "\n",
    "kaggle_images = []\n",
    "kaggle_labels = []\n",
    "\n",
    "for folder in os.listdir(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images'):\n",
    "    for img_name in os.listdir(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images/' + folder):\n",
    "        img = cv2.imread(cwd + '/datasets/kaggle-facial-emotional-recognition-dataset/cropped_images/' + folder + '/' + img_name)\n",
    "        if img is None:\n",
    "            print(\"img is none\")\n",
    "            break\n",
    "        kaggle_images.append(img)\n",
    "        # print(img_name)\n",
    "        # print(img_name.split('.')[0])\n",
    "        kaggle_labels.append(get_number_label_for_string(img_name.split('.')[0]))\n",
    "        \n",
    "print(\"kaggle images: \", len(kaggle_images))\n",
    "print(\"kaggle labels: \", len(kaggle_labels))\n",
    "\n",
    "kaggle_dict = {\n",
    "    'images': kaggle_images,\n",
    "    'labels': kaggle_labels\n",
    "}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hog_features_custom(image):\n",
    "    # hog = cv2.HOGDescriptor()\n",
    "    # # hog_features = hog.compute(image)\n",
    "     # convert the image to grayscale\n",
    "     image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "     image = np.sqrt(image)\n",
    "\n",
    "     G_x = np.zeros_like(image, dtype=np.float32)\n",
    "     G_y = np.zeros_like(image, dtype=np.float32)\n",
    "\n",
    "     for y in range(1, image.shape[0] - 1):\n",
    "        for x in range(1, image.shape[1] - 1):\n",
    "            G_x[y, x] = image[y, x-1] - image[y, x+1]\n",
    "            G_y[y, x] = image[y-1, x] - image[y+1, x]\n",
    "    \n",
    "     G = np.sqrt(np.square(G_x) + np.square(G_y))\n",
    "     theta = np.arctan(G_y, G_x)\n",
    "\n",
    "     # divide the image into 8x8 cells\n",
    "     cells = np.zeros((8, 8, 8), dtype=np.float32)\n",
    "     # for each cell create a local 1-D histogram of gradient orientations that is sorted into 9 angular bins according to their gradient orientation evenly distributed over 0 to 180 degrees\n",
    "     for y in range(0, image.shape[0] - 8, 8):\n",
    "        for x in range(0, image.shape[1] - 8, 8):\n",
    "            for i in range(8):\n",
    "                for j in range(8):\n",
    "                    cells[i, j, int(theta[y+i, x+j] / 20)] += G[y+i, x+j]\n",
    "\n",
    "     # divide the cells within each angular bin divided into blocks with 3x3 cell in size\n",
    "     # for each block, normalize the histogram using L2-normalization approach\n",
    "     hog_features = []\n",
    "     for y in range(0, 6):\n",
    "        for x in range(0, 6):\n",
    "            block = cells[y:y+3, x:x+3].flatten()\n",
    "            block /= np.sqrt(np.sum(np.square(block)) + 1e-5)\n",
    "            hog_features.extend(block)\n",
    "     hog_features = np.array(hog_features)\n",
    "\n",
    "     hog_features = hog_features.flatten()\n",
    "     return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hog_features(image):\n",
    "    # for image that is 64x64\n",
    "    # divide the image into 8x8 cells\n",
    "    cell_size = (8, 8)\n",
    "    block_size = (2, 2)\n",
    "    win_size = (64, 64)\n",
    "\n",
    "    nbins = 9\n",
    "    img_size = (64, 64)\n",
    "    hog = cv2.HOGDescriptor(_winSize=(img_size[1] // cell_size[1] * cell_size[1],\n",
    "                                        img_size[0] // cell_size[0] * cell_size[0]),\n",
    "                                _blockSize=(block_size[1] * cell_size[1],\n",
    "                                            block_size[0] * cell_size[0]),\n",
    "                                _blockStride=(cell_size[1], cell_size[0]),\n",
    "                                _cellSize=(cell_size[1], cell_size[0]),\n",
    "                                _nbins=nbins)\n",
    "    hog_features = hog.compute(image)\n",
    "    hog_features = hog_features.flatten()\n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fold(train, test, classifier):\n",
    "    print(\"size of fold\")\n",
    "    print(\"train: \", len(train['images']))\n",
    "    print(\"test: \", len(test['images']))\n",
    "\n",
    "    # https://www.researchgate.net/publication/221364666_Feature_reduction_using_Cuttlefish_Optimization_Algorithm\n",
    "    #CFA algorithm begins by keeping the feature locations (indices) of a particular dataset in a RankedArray list as follows: RankedArray = [0, 1, 2, …, L − 1], where L represents the feature size. \n",
    "    #After that, it initializes a population (P) with N random solutions, so that each solution Pi is linked with two subsets: SelectedFeatures and UnselectedFeatures, where SelectedFeatures ⊂ RankedArray, UnselectedFeatures ⊂ RankedArray, and SelectedFeatures ⋂ UnselectedFeatures = Ø\n",
    "\n",
    "    # ranked_list variable has the indices of the features in the dataset from 0 to image feature size - 1\n",
    "    ranked_list = np.arange(train['images'][0].shape[0])\n",
    "    print(\"ranked list: \", len(ranked_list))\n",
    "\n",
    "    # get a baseline by taking the label of the majority class and using that as the prediction for all the images\n",
    "    # get the number of images in each class\n",
    "    # create a dictionary with the class as the key and the number of images in that class as the value\n",
    "    class_count = {}\n",
    "    for label in train['labels']:\n",
    "        if label in class_count:\n",
    "            class_count[label] += 1\n",
    "        else:\n",
    "            class_count[label] = 1\n",
    "    print(\"Train class count: \", class_count)\n",
    "    # get the class with the most images\n",
    "    majority_class = max(class_count, key=class_count.get)\n",
    "    print(\"Train majority class: \", majority_class)\n",
    "    # get the accuracy of the majority class\n",
    "    majority_class_accuracy = class_count[majority_class] / len(train['labels'])\n",
    "    print(\"Train majority class accuracy: \", majority_class_accuracy)\n",
    "\n",
    "\n",
    "    # train and test has following structure {'images': [], 'labels': []}\n",
    "\n",
    "    # solution has the following structure list of solution dictionaries which contain the indices of the selected and unselected features\n",
    "    solutions = []\n",
    "    # N = random.randint(1, train['images'][0].shape[0]-1)\n",
    "    N =10\n",
    "    print(\"N: \", N)\n",
    "    for random_solution in range(0, N):\n",
    "        # randomly select the indices of the features no duplicates\n",
    "        indices_for_selected_features = np.random.choice(ranked_list, len(ranked_list), replace=False)\n",
    "        # using the indices_for_selected_features take the indices and put those features aat those indices in the selected_features array\n",
    "        selected_image_features_indices = indices_for_selected_features\n",
    "        unselected_image_features_indices = np.setdiff1d(ranked_list, selected_image_features_indices)\n",
    "        solution = {\n",
    "            'selected_features_indices': selected_image_features_indices,\n",
    "            'unselected_features_indices': unselected_image_features_indices,\n",
    "        }\n",
    "        solutions.append(solution)\n",
    "\n",
    "\n",
    "    # go through each solution in the solutions list and calculate the goodness of the solution\n",
    "    solutions_with_goodness = []\n",
    "\n",
    "    test_last_selected_features_indices = []\n",
    "    test_dupolication_selected_features_indices = []\n",
    "    print(\"solutions: \", len(solutions))\n",
    "    for solution in solutions:\n",
    "        # calculate the goodness of the solution\n",
    "        # goodness = 1 / (1 + error)\n",
    "        # error = 1 - accuracy\n",
    "        # accuracy = svm.score(features[solution[0]], features[solution[1]])\n",
    "\n",
    "        # check if the selected_features_indices is different\n",
    "        if np.array_equal(solution['selected_features_indices'], test_last_selected_features_indices):\n",
    "            print(\"found duplicate solution\")\n",
    "            # remove the solution from the solutions list and exit the loop\n",
    "            solutions.remove(solution)\n",
    "            break\n",
    "        else:\n",
    "            test_last_selected_features_indices = solution['selected_features_indices']\n",
    "            \n",
    "\n",
    "\n",
    "        # get the features at the selected_features_indices\n",
    "        train_images_with_selected_features =[]\n",
    "        for i in range(0, len(train['images'])):\n",
    "            train_images_with_selected_features.append(train['images'][i][solution['selected_features_indices']])\n",
    "            # print(\"unique items in train['images'][i][solution['selected_features_indices']]\", np.unique(train['images'][i][solution['selected_features_indices']]))\n",
    "        test_images_with_selected_features = []\n",
    "        for i in range(0, len(test['images'])):\n",
    "            test_images_with_selected_features.append(test['images'][i][solution['selected_features_indices']])\n",
    "\n",
    "\n",
    "        # check if the train_images_with_selected_features is \n",
    "        if np.array_equal(train_images_with_selected_features, test_dupolication_selected_features_indices):\n",
    "            print(\"found duplicate solution\")\n",
    "            continue\n",
    "        else:\n",
    "            test_dupolication_selected_features_indices = train_images_with_selected_features\n",
    "\n",
    "\n",
    "        classifier.fit(train_images_with_selected_features, train['labels'])\n",
    "        train_prediction = classifier.predict(train_images_with_selected_features)\n",
    "        solution['training_accuracy'] = 1 / (1 + (1 - accuracy_score(train['labels'], train_prediction)))\n",
    "        print(\"solution goodness: \", solution['training_accuracy'])\n",
    "        test_prediction = classifier.predict(test_images_with_selected_features)\n",
    "        solution['testing_accuracy'] = accuracy_score(test['labels'], test_prediction)\n",
    "        solutions_with_goodness.append(solution)\n",
    "\n",
    "    # sort the solutions_with_goodness list in descending order of goodness\n",
    "    solutions_with_goodness.sort(key=lambda x: x['training_accuracy'], reverse=True)\n",
    "\n",
    "    best_solution = solutions_with_goodness[0]\n",
    "\n",
    "    # randomly delete 10% of the features from the selected_features_indices\n",
    "    best_solution['selected_features_indices'] = np.random.choice(best_solution['selected_features_indices'], int(best_solution['selected_features_indices'].shape[0] * 0.9))\n",
    "    \n",
    "    # while the stopping criteria is not met, the algorithm performs the following steps:   \n",
    "    stoping_criteria = 0\n",
    "    while stoping_criteria !=10:\n",
    "        # calculat the CFA of each solution within the population_of_solutions\n",
    "        # for each solution within the population_of_solutions, calculate the CFA\n",
    "        # print(\"N\", N)\n",
    "        nHalf = int(N/2)\n",
    "        K = random.randint(0,nHalf)\n",
    "        for i in range(0, K-1):\n",
    "            r = random.randint(0,len(solutions_with_goodness[i][\"selected_features_indices\"])-1)\n",
    "            v = len(solutions_with_goodness[i][\"selected_features_indices\"]) - r\n",
    "            if (v > len(solutions_with_goodness[i][\"unselected_features_indices\"])):\n",
    "                # cut the selected_features_indices to the size of the selected_features_indices\n",
    "                temp_selected_features_indices = solutions_with_goodness[i][\"selected_features_indices\"]\n",
    "            else:\n",
    "                reflection = random.sample(solutions_with_goodness[i][\"selected_features_indices\"].tolist(), r)\n",
    "                visibility = random.sample(solutions_with_goodness[i][\"unselected_features_indices\"].tolist(), v)\n",
    "            # new subset union of reflection and visibility\n",
    "                temp_selected_features_indices = np.union1d(reflection, visibility)\n",
    "            newSubset = {\n",
    "                'selected_features_indices': temp_selected_features_indices,\n",
    "                'unselected_features_indices': np.setdiff1d(ranked_list, temp_selected_features_indices),\n",
    "            }\n",
    "            # evaluate new subset using the svm\n",
    "            # get the features at the selected_features_indices\n",
    "            train_images_with_selected_features =[]\n",
    "            for j in range(0, len(train['images'])):\n",
    "                train_images_with_selected_features.append(train['images'][j][newSubset[\"selected_features_indices\"]])\n",
    "            test_images_with_selected_features = []\n",
    "            for j in range(0, len(test['images'])):\n",
    "                test_images_with_selected_features.append(test['images'][j][newSubset[\"selected_features_indices\"]])\n",
    "\n",
    "            classifier.fit(train_images_with_selected_features, train['labels'])\n",
    "            train_prediction = classifier.predict(train_images_with_selected_features)\n",
    "            \n",
    "            goodness = 1 / (1 + (1 - accuracy_score(train['labels'], train_prediction)))\n",
    "            test_prediction = classifier.predict(test_images_with_selected_features)\n",
    "            test_accuracy = accuracy_score(test['labels'], test_prediction)\n",
    "\n",
    "            if goodness > solutions_with_goodness[i]['training_accuracy']:\n",
    "                solutions_with_goodness[i]['training_accuracy'] = goodness\n",
    "                solutions_with_goodness[i]['testing_accuracy'] = test_accuracy\n",
    "                solutions_with_goodness[i]['selected_features_indices'] = newSubset[\"selected_features_indices\"]\n",
    "                solutions_with_goodness[i]['unselected_features_indices'] = np.setdiff1d(ranked_list, newSubset[\"selected_features_indices\"])\n",
    "            if goodness > best_solution['training_accuracy']:\n",
    "                best_solution = solutions_with_goodness[i]\n",
    "        newSubset = best_solution\n",
    "        T = 5\n",
    "        for i in range(0, T-1):\n",
    "            # randomly exchange 10% of the features between the selected and unselected features of the newSubset\n",
    "\n",
    "            temp_selected_features_indices = np.random.choice(newSubset['selected_features_indices'], int(newSubset['selected_features_indices'].shape[0] * 0.9))\n",
    "\n",
    "            newSubset = {\n",
    "                'selected_features_indices': temp_selected_features_indices,\n",
    "                'unselected_features_indices': np.setdiff1d(ranked_list, temp_selected_features_indices),\n",
    "            }\n",
    "                \n",
    "            # evaluate new subset using the svm\n",
    "            # get the features at the selected_features_indices\n",
    "            train_images_with_selected_features =[]\n",
    "            for i in range(0, len(train['images'])):\n",
    "                train_images_with_selected_features.append(train['images'][i][newSubset[\"selected_features_indices\"]])\n",
    "            test_images_with_selected_features = []\n",
    "            for i in range(0, len(test['images'])):\n",
    "                test_images_with_selected_features.append(test['images'][i][newSubset[\"selected_features_indices\"]])\n",
    "\n",
    "            classifier.fit(train_images_with_selected_features, train['labels'])\n",
    "            train_predictor = classifier.predict(train_images_with_selected_features)\n",
    "            goodness = 1 / (1 + (1 - accuracy_score(train['labels'], train_predictor)))\n",
    "            test_predictor = classifier.predict(test_images_with_selected_features)\n",
    "            test_accuracy = accuracy_score(test['labels'], test_predictor)\n",
    "            if goodness > best_solution['training_accuracy']:\n",
    "                newSubset[\"goodness\"] = goodness\n",
    "                newSubset[\"testing_accuracy\"] = test_accuracy\n",
    "                best_solution = newSubset\n",
    "        m = 5\n",
    "        size = len(best_solution[\"selected_features_indices\"])\n",
    "        for i in range(0, m-1):\n",
    "            # randomly delete 10% of the features from the selected_features_indices\n",
    "            temp_selected_features_indices = np.random.choice(best_solution['selected_features_indices'], int(size * 0.9))\n",
    "            \n",
    "            new_subset = {\n",
    "                'selected_features_indices': temp_selected_features_indices,\n",
    "                'unselected_features_indices': np.setdiff1d(ranked_list, temp_selected_features_indices),\n",
    "            }\n",
    "            # evaluate new subset using the svm\n",
    "            # get the features at the selected_features_indices\n",
    "            train_images_with_selected_features =[]\n",
    "            for i in range(0, len(train['images'])):\n",
    "                train_images_with_selected_features.append(train['images'][i][new_subset[\"selected_features_indices\"]])\n",
    "            test_images_with_selected_features = []\n",
    "            for i in range(0, len(test['images'])):\n",
    "                test_images_with_selected_features.append(test['images'][i][new_subset[\"selected_features_indices\"]])\n",
    "\n",
    "            classifier.fit(train_images_with_selected_features, train['labels'])\n",
    "            train_prediction = classifier.predict(train_images_with_selected_features)\n",
    "            goodness = 1 / (1 + (1 - accuracy_score(train['labels'], train_prediction)))\n",
    "\n",
    "            test_prediction = classifier.predict(test_images_with_selected_features)\n",
    "            test_accuracy = accuracy_score(test['labels'], test_prediction)\n",
    "            \n",
    "            if goodness > best_solution['training_accuracy']:\n",
    "                new_subset[\"training_accuracy\"] = goodness\n",
    "                new_subset[\"testing_accuracy\"] = test_accuracy\n",
    "                best_solution = new_subset\n",
    "            \n",
    "            for i in range(0, K):\n",
    "                # randomly generate newsubset\n",
    "                temp_selected_features_indices = np.random.choice(ranked_list, N)\n",
    "\n",
    "                new_subset = {\n",
    "                    'selected_features_indices': temp_selected_features_indices,\n",
    "                    'unselected_features_indices': np.setdiff1d(ranked_list, temp_selected_features_indices),\n",
    "                }\n",
    "                # evaluate new subset using the svm\n",
    "                # get the features at the selected_features_indices\n",
    "                train_images_with_selected_features =[]\n",
    "                for j in range(0, len(train['images'])):\n",
    "                    train_images_with_selected_features.append(train['images'][j][new_subset[\"selected_features_indices\"]])\n",
    "                test_images_with_selected_features = []\n",
    "                for j in range(0, len(test['images'])):\n",
    "                    test_images_with_selected_features.append(test['images'][j][new_subset[\"selected_features_indices\"]])\n",
    "                \n",
    "                classifier.fit(train_images_with_selected_features, train['labels'])\n",
    "                train_prediction = classifier.predict(train_images_with_selected_features)\n",
    "                goodness = 1 / (1 + (1 - accuracy_score(train['labels'], train_prediction)))\n",
    "                test_prediction = classifier.predict(test_images_with_selected_features)\n",
    "                test_accuracy = accuracy_score(test['labels'], test_prediction)\n",
    "                if goodness > solutions_with_goodness[i]['training_accuracy']:\n",
    "                    solutions_with_goodness[i]['training_accuracy'] = goodness\n",
    "                    solutions_with_goodness[i]['testing_accuracy'] = test_accuracy\n",
    "                    solutions_with_goodness[i]['selected_features_indices'] = new_subset\n",
    "                    solutions_with_goodness[i]['unselected_features_indices'] = np.setdiff1d(ranked_list, new_subset)\n",
    "                if goodness > best_solution['training_accuracy']:\n",
    "                    best_solution = newSubset\n",
    "                    best_solution['training_accuracy'] = goodness\n",
    "        stoping_criteria += 1\n",
    "    print(\"best solution: \", best_solution)\n",
    "\n",
    "    \n",
    "    results = {\n",
    "        \"training_accuracy\": best_solution['training_accuracy'],\n",
    "        \"testing_accuracy\": best_solution['testing_accuracy'],\n",
    "        \"selected_features_indices\": best_solution['selected_features_indices'],\n",
    "        \"unselected_features_indices\": best_solution['unselected_features_indices'],\n",
    "    }\n",
    "    return results\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "                \n",
    "\n",
    "           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(dataset, classifier):\n",
    "    # split the dataset into five fold cross validation\n",
    "    # create a list of the indexes of the dataset\n",
    "    # shuffle the indexes\n",
    "    # split the indexes into five folds\n",
    "\n",
    "    # shuffle the dataset\n",
    "    # create a list of the indexes of the dataset\n",
    "\n",
    "    # size of the dataset\n",
    "    results = []\n",
    "\n",
    "\n",
    "\n",
    "    print(\"dataset size: \", len(dataset['images']))\n",
    "\n",
    "    dataset_indexes = np.arange(len(dataset['images']))\n",
    "    np.random.shuffle(dataset_indexes)\n",
    "    # split the dataset into five folds\n",
    "    folds_images = np.array_split(dataset_indexes, 5)\n",
    "    folds_labels = np.array_split(dataset_indexes, 5)\n",
    "\n",
    "    # folds_images = np.array_split(dataset[\"images\"], 5)\n",
    "    # folds_labels = np.array_split(dataset[\"labels\"], 5)\n",
    "    folds = []\n",
    "    for i in range(0, len(folds_images)):\n",
    "        fold = {\n",
    "            'images': folds_images[i],\n",
    "            'labels': folds_labels[i]\n",
    "        }\n",
    "        folds.append(fold)\n",
    "    \n",
    "    # create a list of the accuracies for each fold\n",
    "    all_accuracy = [] \n",
    "    # go through each fold\n",
    "    for i in range(0, len(folds)):\n",
    "        testing = folds[i]\n",
    "        ## all the other folds are training\n",
    "        training = {\n",
    "            'images': [],\n",
    "            'labels': []\n",
    "        }\n",
    "        for j in range(0, len(folds)):\n",
    "            if j != i:\n",
    "                training['images'].extend(folds[j]['images'])\n",
    "                training['labels'].extend(folds[j]['labels'])\n",
    "        \n",
    "        # get the the class count for the training set\n",
    "        class_count = {}\n",
    "        for label in training['labels']:\n",
    "            if label in class_count:\n",
    "                class_count[label] += 1\n",
    "            else:\n",
    "                class_count[label] = 1\n",
    "        print(\"Train class count: \", class_count)\n",
    "        # get the class with the most images\n",
    "        majority_class = max(class_count, key=class_count.get)\n",
    "        print(\"Train majority class: \", majority_class)\n",
    "        \n",
    "\n",
    "\n",
    "        train_image_features = []\n",
    "        train_image_labels = []\n",
    "        test_image_features = []\n",
    "        test_image_labels = []\n",
    "\n",
    "        for image in  range(len(training[\"images\"])):\n",
    "            # get the image\n",
    "            img = dataset['images'][image]\n",
    "            # get the label\n",
    "            label = dataset['labels'][image]\n",
    "            # get the hog features\n",
    "            hog_features = generate_hog_features(img)\n",
    "            # add the hog features to the dataset\n",
    "            train_image_features.append(hog_features)\n",
    "            train_image_labels.append(label)\n",
    "        for image in range(len(testing[\"images\"])):\n",
    "            # get the image\n",
    "            img = dataset['images'][image]\n",
    "            # get the label\n",
    "            label = dataset['labels'][image]\n",
    "            # get the hog features\n",
    "            hog_features = generate_hog_features(img)\n",
    "            # add the hog features to the dataset\n",
    "            test_image_features.append(hog_features)\n",
    "            test_image_labels.append(label)\n",
    "        \n",
    "        train = {\n",
    "            'images': train_image_features,\n",
    "            'labels': train_image_labels\n",
    "        }\n",
    "        test = {\n",
    "            'images': test_image_features,\n",
    "            'labels': test_image_labels\n",
    "        }\n",
    "        print(\"testing train\")\n",
    "        print(len(train['images']))\n",
    "        print(len(test['images']))\n",
    "        result = process_fold(train,test, classifier)\n",
    "        results.append(result)\n",
    "    # average the training accuracy for each fold\n",
    "    average_training_accuracy = 0\n",
    "    for result in results:\n",
    "        average_training_accuracy += result['training_accuracy']\n",
    "    average_training_accuracy /= len(results)\n",
    "    print(\"average training accuracy: \", average_training_accuracy)\n",
    "    # average the testing accuracy for each fold\n",
    "    average_testing_accuracy = 0\n",
    "    for result in results:\n",
    "        average_testing_accuracy += result['testing_accuracy']\n",
    "    average_testing_accuracy /= len(results)\n",
    "    print(\"average testing accuracy: \", average_testing_accuracy)\n",
    "\n",
    "    return average_training_accuracy, average_testing_accuracy\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:  881\n",
      "Train class count:  {99: 1, 675: 1, 876: 1, 209: 1, 410: 1, 690: 1, 701: 1, 241: 1, 238: 1, 723: 1, 337: 1, 686: 1, 98: 1, 278: 1, 851: 1, 434: 1, 515: 1, 354: 1, 699: 1, 627: 1, 40: 1, 478: 1, 179: 1, 861: 1, 544: 1, 484: 1, 499: 1, 366: 1, 257: 1, 441: 1, 617: 1, 119: 1, 786: 1, 351: 1, 329: 1, 749: 1, 582: 1, 334: 1, 142: 1, 483: 1, 106: 1, 747: 1, 486: 1, 539: 1, 524: 1, 77: 1, 596: 1, 533: 1, 15: 1, 698: 1, 776: 1, 695: 1, 49: 1, 121: 1, 666: 1, 194: 1, 510: 1, 737: 1, 82: 1, 89: 1, 178: 1, 797: 1, 599: 1, 85: 1, 774: 1, 230: 1, 444: 1, 348: 1, 51: 1, 282: 1, 181: 1, 589: 1, 75: 1, 491: 1, 867: 1, 507: 1, 147: 1, 751: 1, 177: 1, 2: 1, 418: 1, 458: 1, 350: 1, 313: 1, 22: 1, 593: 1, 494: 1, 368: 1, 814: 1, 843: 1, 462: 1, 713: 1, 621: 1, 182: 1, 811: 1, 359: 1, 26: 1, 234: 1, 864: 1, 825: 1, 714: 1, 205: 1, 647: 1, 114: 1, 787: 1, 31: 1, 331: 1, 270: 1, 46: 1, 694: 1, 411: 1, 385: 1, 801: 1, 312: 1, 212: 1, 377: 1, 879: 1, 380: 1, 447: 1, 317: 1, 91: 1, 286: 1, 463: 1, 363: 1, 379: 1, 54: 1, 289: 1, 125: 1, 396: 1, 62: 1, 174: 1, 276: 1, 4: 1, 517: 1, 504: 1, 740: 1, 669: 1, 185: 1, 522: 1, 170: 1, 503: 1, 294: 1, 729: 1, 197: 1, 190: 1, 87: 1, 832: 1, 224: 1, 710: 1, 400: 1, 678: 1, 186: 1, 878: 1, 233: 1, 875: 1, 266: 1, 532: 1, 812: 1, 394: 1, 573: 1, 614: 1, 872: 1, 651: 1, 518: 1, 804: 1, 648: 1, 727: 1, 659: 1, 70: 1, 545: 1, 256: 1, 649: 1, 215: 1, 781: 1, 822: 1, 778: 1, 827: 1, 476: 1, 244: 1, 349: 1, 180: 1, 485: 1, 399: 1, 60: 1, 728: 1, 247: 1, 367: 1, 742: 1, 372: 1, 558: 1, 322: 1, 637: 1, 700: 1, 338: 1, 818: 1, 36: 1, 393: 1, 543: 1, 526: 1, 626: 1, 807: 1, 612: 1, 1: 1, 537: 1, 516: 1, 595: 1, 461: 1, 412: 1, 355: 1, 164: 1, 760: 1, 5: 1, 136: 1, 489: 1, 736: 1, 427: 1, 681: 1, 369: 1, 645: 1, 290: 1, 14: 1, 835: 1, 603: 1, 43: 1, 198: 1, 128: 1, 570: 1, 568: 1, 391: 1, 437: 1, 120: 1, 335: 1, 490: 1, 574: 1, 523: 1, 305: 1, 283: 1, 90: 1, 306: 1, 708: 1, 344: 1, 759: 1, 438: 1, 267: 1, 163: 1, 95: 1, 586: 1, 531: 1, 501: 1, 57: 1, 319: 1, 25: 1, 520: 1, 535: 1, 633: 1, 58: 1, 470: 1, 307: 1, 83: 1, 221: 1, 724: 1, 646: 1, 819: 1, 390: 1, 493: 1, 115: 1, 113: 1, 692: 1, 187: 1, 116: 1, 575: 1, 207: 1, 213: 1, 157: 1, 86: 1, 768: 1, 706: 1, 301: 1, 284: 1, 156: 1, 293: 1, 873: 1, 716: 1, 551: 1, 61: 1, 854: 1, 772: 1, 496: 1, 439: 1, 414: 1, 362: 1, 850: 1, 27: 1, 755: 1, 146: 1, 594: 1, 353: 1, 718: 1, 497: 1, 172: 1, 795: 1, 358: 1, 566: 1, 78: 1, 842: 1, 45: 1, 696: 1, 132: 1, 618: 1, 813: 1, 592: 1, 320: 1, 580: 1, 425: 1, 381: 1, 373: 1, 7: 1, 127: 1, 870: 1, 42: 1, 279: 1, 766: 1, 820: 1, 588: 1, 632: 1, 480: 1, 777: 1, 466: 1, 585: 1, 6: 1, 184: 1, 752: 1, 88: 1, 23: 1, 208: 1, 821: 1, 676: 1, 296: 1, 18: 1, 785: 1, 122: 1, 509: 1, 254: 1, 392: 1, 382: 1, 219: 1, 745: 1, 709: 1, 370: 1, 550: 1, 465: 1, 330: 1, 321: 1, 607: 1, 711: 1, 398: 1, 652: 1, 665: 1, 534: 1, 10: 1, 253: 1, 450: 1, 500: 1, 364: 1, 422: 1, 748: 1, 126: 1, 421: 1, 643: 1, 413: 1, 218: 1, 521: 1, 815: 1, 303: 1, 426: 1, 620: 1, 857: 1, 734: 1, 547: 1, 860: 1, 151: 1, 600: 1, 790: 1, 868: 1, 859: 1, 527: 1, 432: 1, 404: 1, 657: 1, 92: 1, 830: 1, 557: 1, 342: 1, 264: 1, 193: 1, 37: 1, 578: 1, 452: 1, 834: 1, 605: 1, 200: 1, 841: 1, 9: 1, 59: 1, 443: 1, 634: 1, 847: 1, 56: 1, 285: 1, 17: 1, 287: 1, 255: 1, 104: 1, 791: 1, 226: 1, 263: 1, 456: 1, 371: 1, 81: 1, 472: 1, 530: 1, 389: 1, 333: 1, 409: 1, 628: 1, 862: 1, 112: 1, 0: 1, 639: 1, 511: 1, 47: 1, 65: 1, 332: 1, 865: 1, 430: 1, 561: 1, 239: 1, 442: 1, 677: 1, 757: 1, 613: 1, 74: 1, 79: 1, 756: 1, 129: 1, 482: 1, 788: 1, 222: 1, 719: 1, 376: 1, 261: 1, 725: 1, 72: 1, 220: 1, 168: 1, 424: 1, 33: 1, 94: 1, 274: 1, 148: 1, 275: 1, 602: 1, 630: 1, 529: 1, 459: 1, 817: 1, 866: 1, 165: 1, 328: 1, 29: 1, 302: 1, 341: 1, 316: 1, 315: 1, 150: 1, 601: 1, 423: 1, 203: 1, 446: 1, 625: 1, 488: 1, 374: 1, 773: 1, 479: 1, 680: 1, 176: 1, 39: 1, 408: 1, 650: 1, 388: 1, 642: 1, 789: 1, 837: 1, 525: 1, 809: 1, 281: 1, 191: 1, 644: 1, 661: 1, 259: 1, 298: 1, 806: 1, 871: 1, 314: 1, 250: 1, 173: 1, 656: 1, 63: 1, 405: 1, 188: 1, 869: 1, 739: 1, 828: 1, 874: 1, 345: 1, 133: 1, 615: 1, 326: 1, 610: 1, 668: 1, 750: 1, 340: 1, 758: 1, 779: 1, 743: 1, 559: 1, 762: 1, 715: 1, 419: 1, 292: 1, 816: 1, 571: 1, 556: 1, 826: 1, 12: 1, 738: 1, 563: 1, 229: 1, 569: 1, 48: 1, 780: 1, 325: 1, 416: 1, 761: 1, 449: 1, 300: 1, 844: 1, 323: 1, 96: 1, 403: 1, 211: 1, 799: 1, 506: 1, 143: 1, 477: 1, 848: 1, 629: 1, 280: 1, 34: 1, 824: 1, 717: 1, 855: 1, 50: 1, 562: 1, 579: 1, 199: 1, 16: 1, 237: 1, 288: 1, 417: 1, 549: 1, 295: 1, 433: 1, 130: 1, 160: 1, 733: 1, 839: 1, 514: 1, 623: 1, 378: 1, 838: 1, 792: 1, 299: 1, 103: 1, 502: 1, 670: 1, 880: 1, 683: 1, 793: 1, 606: 1, 401: 1, 139: 1, 101: 1, 481: 1, 519: 1, 498: 1, 339: 1, 3: 1, 754: 1, 564: 1, 833: 1, 162: 1, 109: 1, 102: 1, 624: 1, 107: 1, 76: 1, 245: 1, 415: 1, 697: 1, 538: 1, 684: 1, 487: 1, 673: 1, 512: 1, 753: 1, 336: 1, 227: 1, 475: 1, 453: 1, 803: 1, 721: 1, 28: 1, 858: 1, 877: 1, 712: 1, 587: 1, 149: 1, 311: 1, 240: 1, 202: 1, 260: 1, 608: 1, 21: 1, 653: 1, 397: 1, 555: 1, 731: 1, 845: 1, 679: 1, 541: 1, 554: 1, 505: 1, 464: 1, 105: 1, 175: 1, 609: 1, 145: 1, 688: 1, 636: 1, 492: 1, 744: 1, 846: 1, 196: 1, 635: 1, 206: 1, 258: 1, 467: 1, 365: 1, 667: 1, 746: 1, 852: 1, 343: 1, 395: 1, 540: 1, 44: 1, 140: 1, 24: 1, 158: 1, 204: 1, 64: 1, 273: 1, 246: 1, 770: 1, 576: 1, 560: 1, 536: 1, 159: 1, 71: 1, 726: 1, 8: 1, 469: 1, 471: 1, 689: 1, 291: 1, 808: 1, 542: 1, 429: 1, 269: 1, 604: 1, 428: 1, 272: 1, 722: 1, 703: 1, 216: 1, 741: 1, 137: 1, 375: 1, 863: 1, 195: 1, 153: 1, 235: 1, 232: 1, 93: 1}\n",
      "Train majority class:  99\n",
      "testing train\n",
      "704\n",
      "177\n",
      "size of fold\n",
      "train:  704\n",
      "test:  177\n",
      "ranked list:  2592\n",
      "Train class count:  {5: 83, 6: 593, 4: 28}\n",
      "Train majority class:  6\n",
      "Train majority class accuracy:  0.8423295454545454\n",
      "N:  10\n",
      "solutions:  10\n",
      "solution goodness:  0.8638036809815951\n",
      "solution goodness:  0.8638036809815951\n",
      "solution goodness:  0.8638036809815951\n",
      "solution goodness:  0.8638036809815951\n",
      "solution goodness:  0.8638036809815951\n",
      "solution goodness:  0.8638036809815951\n",
      "solution goodness:  0.8638036809815951\n",
      "solution goodness:  0.8638036809815951\n",
      "solution goodness:  0.8638036809815951\n",
      "solution goodness:  0.8638036809815951\n",
      "best solution:  {'selected_features_indices': array([2524, 1707, 2130, ..., 1465, 1600,  112]), 'unselected_features_indices': array([], dtype=int64), 'training_accuracy': 0.8638036809815951, 'testing_accuracy': 0.5310734463276836}\n",
      "Train class count:  {451: 1, 460: 1, 161: 1, 231: 1, 66: 1, 616: 1, 386: 1, 135: 1, 327: 1, 84: 1, 11: 1, 201: 1, 597: 1, 265: 1, 707: 1, 262: 1, 144: 1, 805: 1, 528: 1, 167: 1, 840: 1, 671: 1, 271: 1, 223: 1, 767: 1, 829: 1, 318: 1, 357: 1, 457: 1, 436: 1, 67: 1, 581: 1, 655: 1, 552: 1, 440: 1, 611: 1, 38: 1, 641: 1, 823: 1, 118: 1, 730: 1, 548: 1, 682: 1, 836: 1, 474: 1, 546: 1, 402: 1, 297: 1, 775: 1, 110: 1, 619: 1, 853: 1, 769: 1, 361: 1, 35: 1, 155: 1, 732: 1, 654: 1, 192: 1, 154: 1, 735: 1, 468: 1, 383: 1, 111: 1, 567: 1, 189: 1, 217: 1, 68: 1, 32: 1, 798: 1, 308: 1, 577: 1, 782: 1, 53: 1, 406: 1, 454: 1, 108: 1, 214: 1, 73: 1, 664: 1, 810: 1, 455: 1, 631: 1, 508: 1, 764: 1, 638: 1, 304: 1, 763: 1, 52: 1, 591: 1, 771: 1, 572: 1, 407: 1, 360: 1, 152: 1, 849: 1, 141: 1, 248: 1, 765: 1, 705: 1, 124: 1, 277: 1, 69: 1, 131: 1, 249: 1, 796: 1, 598: 1, 794: 1, 80: 1, 663: 1, 243: 1, 553: 1, 251: 1, 693: 1, 583: 1, 117: 1, 590: 1, 674: 1, 236: 1, 384: 1, 30: 1, 622: 1, 691: 1, 435: 1, 171: 1, 309: 1, 41: 1, 310: 1, 123: 1, 704: 1, 702: 1, 352: 1, 448: 1, 495: 1, 166: 1, 420: 1, 856: 1, 640: 1, 685: 1, 831: 1, 252: 1, 242: 1, 431: 1, 228: 1, 169: 1, 783: 1, 356: 1, 802: 1, 387: 1, 324: 1, 19: 1, 800: 1, 225: 1, 565: 1, 138: 1, 347: 1, 473: 1, 100: 1, 183: 1, 97: 1, 672: 1, 784: 1, 445: 1, 210: 1, 268: 1, 658: 1, 662: 1, 20: 1, 134: 1, 687: 1, 513: 1, 660: 1, 13: 1, 720: 1, 584: 1, 346: 1, 55: 1, 827: 1, 476: 1, 244: 1, 349: 1, 180: 1, 485: 1, 399: 1, 60: 1, 728: 1, 247: 1, 367: 1, 742: 1, 372: 1, 558: 1, 322: 1, 637: 1, 700: 1, 338: 1, 818: 1, 36: 1, 393: 1, 543: 1, 526: 1, 626: 1, 807: 1, 612: 1, 1: 1, 537: 1, 516: 1, 595: 1, 461: 1, 412: 1, 355: 1, 164: 1, 760: 1, 5: 1, 136: 1, 489: 1, 736: 1, 427: 1, 681: 1, 369: 1, 645: 1, 290: 1, 14: 1, 835: 1, 603: 1, 43: 1, 198: 1, 128: 1, 570: 1, 568: 1, 391: 1, 437: 1, 120: 1, 335: 1, 490: 1, 574: 1, 523: 1, 305: 1, 283: 1, 90: 1, 306: 1, 708: 1, 344: 1, 759: 1, 438: 1, 267: 1, 163: 1, 95: 1, 586: 1, 531: 1, 501: 1, 57: 1, 319: 1, 25: 1, 520: 1, 535: 1, 633: 1, 58: 1, 470: 1, 307: 1, 83: 1, 221: 1, 724: 1, 646: 1, 819: 1, 390: 1, 493: 1, 115: 1, 113: 1, 692: 1, 187: 1, 116: 1, 575: 1, 207: 1, 213: 1, 157: 1, 86: 1, 768: 1, 706: 1, 301: 1, 284: 1, 156: 1, 293: 1, 873: 1, 716: 1, 551: 1, 61: 1, 854: 1, 772: 1, 496: 1, 439: 1, 414: 1, 362: 1, 850: 1, 27: 1, 755: 1, 146: 1, 594: 1, 353: 1, 718: 1, 497: 1, 172: 1, 795: 1, 358: 1, 566: 1, 78: 1, 842: 1, 45: 1, 696: 1, 132: 1, 618: 1, 813: 1, 592: 1, 320: 1, 580: 1, 425: 1, 381: 1, 373: 1, 7: 1, 127: 1, 870: 1, 42: 1, 279: 1, 766: 1, 820: 1, 588: 1, 632: 1, 480: 1, 777: 1, 466: 1, 585: 1, 6: 1, 184: 1, 752: 1, 88: 1, 23: 1, 208: 1, 821: 1, 676: 1, 296: 1, 18: 1, 785: 1, 122: 1, 509: 1, 254: 1, 392: 1, 382: 1, 219: 1, 745: 1, 709: 1, 370: 1, 550: 1, 465: 1, 330: 1, 321: 1, 607: 1, 711: 1, 398: 1, 652: 1, 665: 1, 534: 1, 10: 1, 253: 1, 450: 1, 500: 1, 364: 1, 422: 1, 748: 1, 126: 1, 421: 1, 643: 1, 413: 1, 218: 1, 521: 1, 815: 1, 303: 1, 426: 1, 620: 1, 857: 1, 734: 1, 547: 1, 860: 1, 151: 1, 600: 1, 790: 1, 868: 1, 859: 1, 527: 1, 432: 1, 404: 1, 657: 1, 92: 1, 830: 1, 557: 1, 342: 1, 264: 1, 193: 1, 37: 1, 578: 1, 452: 1, 834: 1, 605: 1, 200: 1, 841: 1, 9: 1, 59: 1, 443: 1, 634: 1, 847: 1, 56: 1, 285: 1, 17: 1, 287: 1, 255: 1, 104: 1, 791: 1, 226: 1, 263: 1, 456: 1, 371: 1, 81: 1, 472: 1, 530: 1, 389: 1, 333: 1, 409: 1, 628: 1, 862: 1, 112: 1, 0: 1, 639: 1, 511: 1, 47: 1, 65: 1, 332: 1, 865: 1, 430: 1, 561: 1, 239: 1, 442: 1, 677: 1, 757: 1, 613: 1, 74: 1, 79: 1, 756: 1, 129: 1, 482: 1, 788: 1, 222: 1, 719: 1, 376: 1, 261: 1, 725: 1, 72: 1, 220: 1, 168: 1, 424: 1, 33: 1, 94: 1, 274: 1, 148: 1, 275: 1, 602: 1, 630: 1, 529: 1, 459: 1, 817: 1, 866: 1, 165: 1, 328: 1, 29: 1, 302: 1, 341: 1, 316: 1, 315: 1, 150: 1, 601: 1, 423: 1, 203: 1, 446: 1, 625: 1, 488: 1, 374: 1, 773: 1, 479: 1, 680: 1, 176: 1, 39: 1, 408: 1, 650: 1, 388: 1, 642: 1, 789: 1, 837: 1, 525: 1, 809: 1, 281: 1, 191: 1, 644: 1, 661: 1, 259: 1, 298: 1, 806: 1, 871: 1, 314: 1, 250: 1, 173: 1, 656: 1, 63: 1, 405: 1, 188: 1, 869: 1, 739: 1, 828: 1, 874: 1, 345: 1, 133: 1, 615: 1, 326: 1, 610: 1, 668: 1, 750: 1, 340: 1, 758: 1, 779: 1, 743: 1, 559: 1, 762: 1, 715: 1, 419: 1, 292: 1, 816: 1, 571: 1, 556: 1, 826: 1, 12: 1, 738: 1, 563: 1, 229: 1, 569: 1, 48: 1, 780: 1, 325: 1, 416: 1, 761: 1, 449: 1, 300: 1, 844: 1, 323: 1, 96: 1, 403: 1, 211: 1, 799: 1, 506: 1, 143: 1, 477: 1, 848: 1, 629: 1, 280: 1, 34: 1, 824: 1, 717: 1, 855: 1, 50: 1, 562: 1, 579: 1, 199: 1, 16: 1, 237: 1, 288: 1, 417: 1, 549: 1, 295: 1, 433: 1, 130: 1, 160: 1, 733: 1, 839: 1, 514: 1, 623: 1, 378: 1, 838: 1, 792: 1, 299: 1, 103: 1, 502: 1, 670: 1, 880: 1, 683: 1, 793: 1, 606: 1, 401: 1, 139: 1, 101: 1, 481: 1, 519: 1, 498: 1, 339: 1, 3: 1, 754: 1, 564: 1, 833: 1, 162: 1, 109: 1, 102: 1, 624: 1, 107: 1, 76: 1, 245: 1, 415: 1, 697: 1, 538: 1, 684: 1, 487: 1, 673: 1, 512: 1, 753: 1, 336: 1, 227: 1, 475: 1, 453: 1, 803: 1, 721: 1, 28: 1, 858: 1, 877: 1, 712: 1, 587: 1, 149: 1, 311: 1, 240: 1, 202: 1, 260: 1, 608: 1, 21: 1, 653: 1, 397: 1, 555: 1, 731: 1, 845: 1, 679: 1, 541: 1, 554: 1, 505: 1, 464: 1, 105: 1, 175: 1, 609: 1, 145: 1, 688: 1, 636: 1, 492: 1, 744: 1, 846: 1, 196: 1, 635: 1, 206: 1, 258: 1, 467: 1, 365: 1, 667: 1, 746: 1, 852: 1, 343: 1, 395: 1, 540: 1, 44: 1, 140: 1, 24: 1, 158: 1, 204: 1, 64: 1, 273: 1, 246: 1, 770: 1, 576: 1, 560: 1, 536: 1, 159: 1, 71: 1, 726: 1, 8: 1, 469: 1, 471: 1, 689: 1, 291: 1, 808: 1, 542: 1, 429: 1, 269: 1, 604: 1, 428: 1, 272: 1, 722: 1, 703: 1, 216: 1, 741: 1, 137: 1, 375: 1, 863: 1, 195: 1, 153: 1, 235: 1, 232: 1, 93: 1}\n",
      "Train majority class:  451\n",
      "testing train\n",
      "705\n",
      "176\n",
      "size of fold\n",
      "train:  705\n",
      "test:  176\n",
      "ranked list:  2592\n",
      "Train class count:  {5: 83, 6: 593, 4: 28, 7: 1}\n",
      "Train majority class:  6\n",
      "Train majority class accuracy:  0.8411347517730496\n",
      "N:  10\n",
      "solutions:  10\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "best solution:  {'selected_features_indices': array([ 107,  437,  229, ..., 2165,  551,  400]), 'unselected_features_indices': array([], dtype=int64), 'training_accuracy': 0.8629130966952264, 'testing_accuracy': 0.5284090909090909}\n",
      "Train class count:  {451: 1, 460: 1, 161: 1, 231: 1, 66: 1, 616: 1, 386: 1, 135: 1, 327: 1, 84: 1, 11: 1, 201: 1, 597: 1, 265: 1, 707: 1, 262: 1, 144: 1, 805: 1, 528: 1, 167: 1, 840: 1, 671: 1, 271: 1, 223: 1, 767: 1, 829: 1, 318: 1, 357: 1, 457: 1, 436: 1, 67: 1, 581: 1, 655: 1, 552: 1, 440: 1, 611: 1, 38: 1, 641: 1, 823: 1, 118: 1, 730: 1, 548: 1, 682: 1, 836: 1, 474: 1, 546: 1, 402: 1, 297: 1, 775: 1, 110: 1, 619: 1, 853: 1, 769: 1, 361: 1, 35: 1, 155: 1, 732: 1, 654: 1, 192: 1, 154: 1, 735: 1, 468: 1, 383: 1, 111: 1, 567: 1, 189: 1, 217: 1, 68: 1, 32: 1, 798: 1, 308: 1, 577: 1, 782: 1, 53: 1, 406: 1, 454: 1, 108: 1, 214: 1, 73: 1, 664: 1, 810: 1, 455: 1, 631: 1, 508: 1, 764: 1, 638: 1, 304: 1, 763: 1, 52: 1, 591: 1, 771: 1, 572: 1, 407: 1, 360: 1, 152: 1, 849: 1, 141: 1, 248: 1, 765: 1, 705: 1, 124: 1, 277: 1, 69: 1, 131: 1, 249: 1, 796: 1, 598: 1, 794: 1, 80: 1, 663: 1, 243: 1, 553: 1, 251: 1, 693: 1, 583: 1, 117: 1, 590: 1, 674: 1, 236: 1, 384: 1, 30: 1, 622: 1, 691: 1, 435: 1, 171: 1, 309: 1, 41: 1, 310: 1, 123: 1, 704: 1, 702: 1, 352: 1, 448: 1, 495: 1, 166: 1, 420: 1, 856: 1, 640: 1, 685: 1, 831: 1, 252: 1, 242: 1, 431: 1, 228: 1, 169: 1, 783: 1, 356: 1, 802: 1, 387: 1, 324: 1, 19: 1, 800: 1, 225: 1, 565: 1, 138: 1, 347: 1, 473: 1, 100: 1, 183: 1, 97: 1, 672: 1, 784: 1, 445: 1, 210: 1, 268: 1, 658: 1, 662: 1, 20: 1, 134: 1, 687: 1, 513: 1, 660: 1, 13: 1, 720: 1, 584: 1, 346: 1, 55: 1, 99: 1, 675: 1, 876: 1, 209: 1, 410: 1, 690: 1, 701: 1, 241: 1, 238: 1, 723: 1, 337: 1, 686: 1, 98: 1, 278: 1, 851: 1, 434: 1, 515: 1, 354: 1, 699: 1, 627: 1, 40: 1, 478: 1, 179: 1, 861: 1, 544: 1, 484: 1, 499: 1, 366: 1, 257: 1, 441: 1, 617: 1, 119: 1, 786: 1, 351: 1, 329: 1, 749: 1, 582: 1, 334: 1, 142: 1, 483: 1, 106: 1, 747: 1, 486: 1, 539: 1, 524: 1, 77: 1, 596: 1, 533: 1, 15: 1, 698: 1, 776: 1, 695: 1, 49: 1, 121: 1, 666: 1, 194: 1, 510: 1, 737: 1, 82: 1, 89: 1, 178: 1, 797: 1, 599: 1, 85: 1, 774: 1, 230: 1, 444: 1, 348: 1, 51: 1, 282: 1, 181: 1, 589: 1, 75: 1, 491: 1, 867: 1, 507: 1, 147: 1, 751: 1, 177: 1, 2: 1, 418: 1, 458: 1, 350: 1, 313: 1, 22: 1, 593: 1, 494: 1, 368: 1, 814: 1, 843: 1, 462: 1, 713: 1, 621: 1, 182: 1, 811: 1, 359: 1, 26: 1, 234: 1, 864: 1, 825: 1, 714: 1, 205: 1, 647: 1, 114: 1, 787: 1, 31: 1, 331: 1, 270: 1, 46: 1, 694: 1, 411: 1, 385: 1, 801: 1, 312: 1, 212: 1, 377: 1, 879: 1, 380: 1, 447: 1, 317: 1, 91: 1, 286: 1, 463: 1, 363: 1, 379: 1, 54: 1, 289: 1, 125: 1, 396: 1, 62: 1, 174: 1, 276: 1, 4: 1, 517: 1, 504: 1, 740: 1, 669: 1, 185: 1, 522: 1, 170: 1, 503: 1, 294: 1, 729: 1, 197: 1, 190: 1, 87: 1, 832: 1, 224: 1, 710: 1, 400: 1, 678: 1, 186: 1, 878: 1, 233: 1, 875: 1, 266: 1, 532: 1, 812: 1, 394: 1, 573: 1, 614: 1, 872: 1, 651: 1, 518: 1, 804: 1, 648: 1, 727: 1, 659: 1, 70: 1, 545: 1, 256: 1, 649: 1, 215: 1, 781: 1, 822: 1, 778: 1, 321: 1, 607: 1, 711: 1, 398: 1, 652: 1, 665: 1, 534: 1, 10: 1, 253: 1, 450: 1, 500: 1, 364: 1, 422: 1, 748: 1, 126: 1, 421: 1, 643: 1, 413: 1, 218: 1, 521: 1, 815: 1, 303: 1, 426: 1, 620: 1, 857: 1, 734: 1, 547: 1, 860: 1, 151: 1, 600: 1, 790: 1, 868: 1, 859: 1, 527: 1, 432: 1, 404: 1, 657: 1, 92: 1, 830: 1, 557: 1, 342: 1, 264: 1, 193: 1, 37: 1, 578: 1, 452: 1, 834: 1, 605: 1, 200: 1, 841: 1, 9: 1, 59: 1, 443: 1, 634: 1, 847: 1, 56: 1, 285: 1, 17: 1, 287: 1, 255: 1, 104: 1, 791: 1, 226: 1, 263: 1, 456: 1, 371: 1, 81: 1, 472: 1, 530: 1, 389: 1, 333: 1, 409: 1, 628: 1, 862: 1, 112: 1, 0: 1, 639: 1, 511: 1, 47: 1, 65: 1, 332: 1, 865: 1, 430: 1, 561: 1, 239: 1, 442: 1, 677: 1, 757: 1, 613: 1, 74: 1, 79: 1, 756: 1, 129: 1, 482: 1, 788: 1, 222: 1, 719: 1, 376: 1, 261: 1, 725: 1, 72: 1, 220: 1, 168: 1, 424: 1, 33: 1, 94: 1, 274: 1, 148: 1, 275: 1, 602: 1, 630: 1, 529: 1, 459: 1, 817: 1, 866: 1, 165: 1, 328: 1, 29: 1, 302: 1, 341: 1, 316: 1, 315: 1, 150: 1, 601: 1, 423: 1, 203: 1, 446: 1, 625: 1, 488: 1, 374: 1, 773: 1, 479: 1, 680: 1, 176: 1, 39: 1, 408: 1, 650: 1, 388: 1, 642: 1, 789: 1, 837: 1, 525: 1, 809: 1, 281: 1, 191: 1, 644: 1, 661: 1, 259: 1, 298: 1, 806: 1, 871: 1, 314: 1, 250: 1, 173: 1, 656: 1, 63: 1, 405: 1, 188: 1, 869: 1, 739: 1, 828: 1, 874: 1, 345: 1, 133: 1, 615: 1, 326: 1, 610: 1, 668: 1, 750: 1, 340: 1, 758: 1, 779: 1, 743: 1, 559: 1, 762: 1, 715: 1, 419: 1, 292: 1, 816: 1, 571: 1, 556: 1, 826: 1, 12: 1, 738: 1, 563: 1, 229: 1, 569: 1, 48: 1, 780: 1, 325: 1, 416: 1, 761: 1, 449: 1, 300: 1, 844: 1, 323: 1, 96: 1, 403: 1, 211: 1, 799: 1, 506: 1, 143: 1, 477: 1, 848: 1, 629: 1, 280: 1, 34: 1, 824: 1, 717: 1, 855: 1, 50: 1, 562: 1, 579: 1, 199: 1, 16: 1, 237: 1, 288: 1, 417: 1, 549: 1, 295: 1, 433: 1, 130: 1, 160: 1, 733: 1, 839: 1, 514: 1, 623: 1, 378: 1, 838: 1, 792: 1, 299: 1, 103: 1, 502: 1, 670: 1, 880: 1, 683: 1, 793: 1, 606: 1, 401: 1, 139: 1, 101: 1, 481: 1, 519: 1, 498: 1, 339: 1, 3: 1, 754: 1, 564: 1, 833: 1, 162: 1, 109: 1, 102: 1, 624: 1, 107: 1, 76: 1, 245: 1, 415: 1, 697: 1, 538: 1, 684: 1, 487: 1, 673: 1, 512: 1, 753: 1, 336: 1, 227: 1, 475: 1, 453: 1, 803: 1, 721: 1, 28: 1, 858: 1, 877: 1, 712: 1, 587: 1, 149: 1, 311: 1, 240: 1, 202: 1, 260: 1, 608: 1, 21: 1, 653: 1, 397: 1, 555: 1, 731: 1, 845: 1, 679: 1, 541: 1, 554: 1, 505: 1, 464: 1, 105: 1, 175: 1, 609: 1, 145: 1, 688: 1, 636: 1, 492: 1, 744: 1, 846: 1, 196: 1, 635: 1, 206: 1, 258: 1, 467: 1, 365: 1, 667: 1, 746: 1, 852: 1, 343: 1, 395: 1, 540: 1, 44: 1, 140: 1, 24: 1, 158: 1, 204: 1, 64: 1, 273: 1, 246: 1, 770: 1, 576: 1, 560: 1, 536: 1, 159: 1, 71: 1, 726: 1, 8: 1, 469: 1, 471: 1, 689: 1, 291: 1, 808: 1, 542: 1, 429: 1, 269: 1, 604: 1, 428: 1, 272: 1, 722: 1, 703: 1, 216: 1, 741: 1, 137: 1, 375: 1, 863: 1, 195: 1, 153: 1, 235: 1, 232: 1, 93: 1}\n",
      "Train majority class:  451\n",
      "testing train\n",
      "705\n",
      "176\n",
      "size of fold\n",
      "train:  705\n",
      "test:  176\n",
      "ranked list:  2592\n",
      "Train class count:  {5: 83, 6: 593, 4: 28, 7: 1}\n",
      "Train majority class:  6\n",
      "Train majority class accuracy:  0.8411347517730496\n",
      "N:  10\n",
      "solutions:  10\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "best solution:  {'selected_features_indices': array([2054, 1328,  923, ...,  600, 1275, 2292]), 'unselected_features_indices': array([], dtype=int64), 'training_accuracy': 0.8629130966952264, 'testing_accuracy': 0.5284090909090909}\n",
      "Train class count:  {451: 1, 460: 1, 161: 1, 231: 1, 66: 1, 616: 1, 386: 1, 135: 1, 327: 1, 84: 1, 11: 1, 201: 1, 597: 1, 265: 1, 707: 1, 262: 1, 144: 1, 805: 1, 528: 1, 167: 1, 840: 1, 671: 1, 271: 1, 223: 1, 767: 1, 829: 1, 318: 1, 357: 1, 457: 1, 436: 1, 67: 1, 581: 1, 655: 1, 552: 1, 440: 1, 611: 1, 38: 1, 641: 1, 823: 1, 118: 1, 730: 1, 548: 1, 682: 1, 836: 1, 474: 1, 546: 1, 402: 1, 297: 1, 775: 1, 110: 1, 619: 1, 853: 1, 769: 1, 361: 1, 35: 1, 155: 1, 732: 1, 654: 1, 192: 1, 154: 1, 735: 1, 468: 1, 383: 1, 111: 1, 567: 1, 189: 1, 217: 1, 68: 1, 32: 1, 798: 1, 308: 1, 577: 1, 782: 1, 53: 1, 406: 1, 454: 1, 108: 1, 214: 1, 73: 1, 664: 1, 810: 1, 455: 1, 631: 1, 508: 1, 764: 1, 638: 1, 304: 1, 763: 1, 52: 1, 591: 1, 771: 1, 572: 1, 407: 1, 360: 1, 152: 1, 849: 1, 141: 1, 248: 1, 765: 1, 705: 1, 124: 1, 277: 1, 69: 1, 131: 1, 249: 1, 796: 1, 598: 1, 794: 1, 80: 1, 663: 1, 243: 1, 553: 1, 251: 1, 693: 1, 583: 1, 117: 1, 590: 1, 674: 1, 236: 1, 384: 1, 30: 1, 622: 1, 691: 1, 435: 1, 171: 1, 309: 1, 41: 1, 310: 1, 123: 1, 704: 1, 702: 1, 352: 1, 448: 1, 495: 1, 166: 1, 420: 1, 856: 1, 640: 1, 685: 1, 831: 1, 252: 1, 242: 1, 431: 1, 228: 1, 169: 1, 783: 1, 356: 1, 802: 1, 387: 1, 324: 1, 19: 1, 800: 1, 225: 1, 565: 1, 138: 1, 347: 1, 473: 1, 100: 1, 183: 1, 97: 1, 672: 1, 784: 1, 445: 1, 210: 1, 268: 1, 658: 1, 662: 1, 20: 1, 134: 1, 687: 1, 513: 1, 660: 1, 13: 1, 720: 1, 584: 1, 346: 1, 55: 1, 99: 1, 675: 1, 876: 1, 209: 1, 410: 1, 690: 1, 701: 1, 241: 1, 238: 1, 723: 1, 337: 1, 686: 1, 98: 1, 278: 1, 851: 1, 434: 1, 515: 1, 354: 1, 699: 1, 627: 1, 40: 1, 478: 1, 179: 1, 861: 1, 544: 1, 484: 1, 499: 1, 366: 1, 257: 1, 441: 1, 617: 1, 119: 1, 786: 1, 351: 1, 329: 1, 749: 1, 582: 1, 334: 1, 142: 1, 483: 1, 106: 1, 747: 1, 486: 1, 539: 1, 524: 1, 77: 1, 596: 1, 533: 1, 15: 1, 698: 1, 776: 1, 695: 1, 49: 1, 121: 1, 666: 1, 194: 1, 510: 1, 737: 1, 82: 1, 89: 1, 178: 1, 797: 1, 599: 1, 85: 1, 774: 1, 230: 1, 444: 1, 348: 1, 51: 1, 282: 1, 181: 1, 589: 1, 75: 1, 491: 1, 867: 1, 507: 1, 147: 1, 751: 1, 177: 1, 2: 1, 418: 1, 458: 1, 350: 1, 313: 1, 22: 1, 593: 1, 494: 1, 368: 1, 814: 1, 843: 1, 462: 1, 713: 1, 621: 1, 182: 1, 811: 1, 359: 1, 26: 1, 234: 1, 864: 1, 825: 1, 714: 1, 205: 1, 647: 1, 114: 1, 787: 1, 31: 1, 331: 1, 270: 1, 46: 1, 694: 1, 411: 1, 385: 1, 801: 1, 312: 1, 212: 1, 377: 1, 879: 1, 380: 1, 447: 1, 317: 1, 91: 1, 286: 1, 463: 1, 363: 1, 379: 1, 54: 1, 289: 1, 125: 1, 396: 1, 62: 1, 174: 1, 276: 1, 4: 1, 517: 1, 504: 1, 740: 1, 669: 1, 185: 1, 522: 1, 170: 1, 503: 1, 294: 1, 729: 1, 197: 1, 190: 1, 87: 1, 832: 1, 224: 1, 710: 1, 400: 1, 678: 1, 186: 1, 878: 1, 233: 1, 875: 1, 266: 1, 532: 1, 812: 1, 394: 1, 573: 1, 614: 1, 872: 1, 651: 1, 518: 1, 804: 1, 648: 1, 727: 1, 659: 1, 70: 1, 545: 1, 256: 1, 649: 1, 215: 1, 781: 1, 822: 1, 778: 1, 827: 1, 476: 1, 244: 1, 349: 1, 180: 1, 485: 1, 399: 1, 60: 1, 728: 1, 247: 1, 367: 1, 742: 1, 372: 1, 558: 1, 322: 1, 637: 1, 700: 1, 338: 1, 818: 1, 36: 1, 393: 1, 543: 1, 526: 1, 626: 1, 807: 1, 612: 1, 1: 1, 537: 1, 516: 1, 595: 1, 461: 1, 412: 1, 355: 1, 164: 1, 760: 1, 5: 1, 136: 1, 489: 1, 736: 1, 427: 1, 681: 1, 369: 1, 645: 1, 290: 1, 14: 1, 835: 1, 603: 1, 43: 1, 198: 1, 128: 1, 570: 1, 568: 1, 391: 1, 437: 1, 120: 1, 335: 1, 490: 1, 574: 1, 523: 1, 305: 1, 283: 1, 90: 1, 306: 1, 708: 1, 344: 1, 759: 1, 438: 1, 267: 1, 163: 1, 95: 1, 586: 1, 531: 1, 501: 1, 57: 1, 319: 1, 25: 1, 520: 1, 535: 1, 633: 1, 58: 1, 470: 1, 307: 1, 83: 1, 221: 1, 724: 1, 646: 1, 819: 1, 390: 1, 493: 1, 115: 1, 113: 1, 692: 1, 187: 1, 116: 1, 575: 1, 207: 1, 213: 1, 157: 1, 86: 1, 768: 1, 706: 1, 301: 1, 284: 1, 156: 1, 293: 1, 873: 1, 716: 1, 551: 1, 61: 1, 854: 1, 772: 1, 496: 1, 439: 1, 414: 1, 362: 1, 850: 1, 27: 1, 755: 1, 146: 1, 594: 1, 353: 1, 718: 1, 497: 1, 172: 1, 795: 1, 358: 1, 566: 1, 78: 1, 842: 1, 45: 1, 696: 1, 132: 1, 618: 1, 813: 1, 592: 1, 320: 1, 580: 1, 425: 1, 381: 1, 373: 1, 7: 1, 127: 1, 870: 1, 42: 1, 279: 1, 766: 1, 820: 1, 588: 1, 632: 1, 480: 1, 777: 1, 466: 1, 585: 1, 6: 1, 184: 1, 752: 1, 88: 1, 23: 1, 208: 1, 821: 1, 676: 1, 296: 1, 18: 1, 785: 1, 122: 1, 509: 1, 254: 1, 392: 1, 382: 1, 219: 1, 745: 1, 709: 1, 370: 1, 550: 1, 465: 1, 330: 1, 419: 1, 292: 1, 816: 1, 571: 1, 556: 1, 826: 1, 12: 1, 738: 1, 563: 1, 229: 1, 569: 1, 48: 1, 780: 1, 325: 1, 416: 1, 761: 1, 449: 1, 300: 1, 844: 1, 323: 1, 96: 1, 403: 1, 211: 1, 799: 1, 506: 1, 143: 1, 477: 1, 848: 1, 629: 1, 280: 1, 34: 1, 824: 1, 717: 1, 855: 1, 50: 1, 562: 1, 579: 1, 199: 1, 16: 1, 237: 1, 288: 1, 417: 1, 549: 1, 295: 1, 433: 1, 130: 1, 160: 1, 733: 1, 839: 1, 514: 1, 623: 1, 378: 1, 838: 1, 792: 1, 299: 1, 103: 1, 502: 1, 670: 1, 880: 1, 683: 1, 793: 1, 606: 1, 401: 1, 139: 1, 101: 1, 481: 1, 519: 1, 498: 1, 339: 1, 3: 1, 754: 1, 564: 1, 833: 1, 162: 1, 109: 1, 102: 1, 624: 1, 107: 1, 76: 1, 245: 1, 415: 1, 697: 1, 538: 1, 684: 1, 487: 1, 673: 1, 512: 1, 753: 1, 336: 1, 227: 1, 475: 1, 453: 1, 803: 1, 721: 1, 28: 1, 858: 1, 877: 1, 712: 1, 587: 1, 149: 1, 311: 1, 240: 1, 202: 1, 260: 1, 608: 1, 21: 1, 653: 1, 397: 1, 555: 1, 731: 1, 845: 1, 679: 1, 541: 1, 554: 1, 505: 1, 464: 1, 105: 1, 175: 1, 609: 1, 145: 1, 688: 1, 636: 1, 492: 1, 744: 1, 846: 1, 196: 1, 635: 1, 206: 1, 258: 1, 467: 1, 365: 1, 667: 1, 746: 1, 852: 1, 343: 1, 395: 1, 540: 1, 44: 1, 140: 1, 24: 1, 158: 1, 204: 1, 64: 1, 273: 1, 246: 1, 770: 1, 576: 1, 560: 1, 536: 1, 159: 1, 71: 1, 726: 1, 8: 1, 469: 1, 471: 1, 689: 1, 291: 1, 808: 1, 542: 1, 429: 1, 269: 1, 604: 1, 428: 1, 272: 1, 722: 1, 703: 1, 216: 1, 741: 1, 137: 1, 375: 1, 863: 1, 195: 1, 153: 1, 235: 1, 232: 1, 93: 1}\n",
      "Train majority class:  451\n",
      "testing train\n",
      "705\n",
      "176\n",
      "size of fold\n",
      "train:  705\n",
      "test:  176\n",
      "ranked list:  2592\n",
      "Train class count:  {5: 83, 6: 593, 4: 28, 7: 1}\n",
      "Train majority class:  6\n",
      "Train majority class accuracy:  0.8411347517730496\n",
      "N:  10\n",
      "solutions:  10\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "best solution:  {'selected_features_indices': array([2321,  796,  679, ..., 1815,  170, 1329]), 'unselected_features_indices': array([], dtype=int64), 'training_accuracy': 0.8629130966952264, 'testing_accuracy': 0.5284090909090909}\n",
      "Train class count:  {451: 1, 460: 1, 161: 1, 231: 1, 66: 1, 616: 1, 386: 1, 135: 1, 327: 1, 84: 1, 11: 1, 201: 1, 597: 1, 265: 1, 707: 1, 262: 1, 144: 1, 805: 1, 528: 1, 167: 1, 840: 1, 671: 1, 271: 1, 223: 1, 767: 1, 829: 1, 318: 1, 357: 1, 457: 1, 436: 1, 67: 1, 581: 1, 655: 1, 552: 1, 440: 1, 611: 1, 38: 1, 641: 1, 823: 1, 118: 1, 730: 1, 548: 1, 682: 1, 836: 1, 474: 1, 546: 1, 402: 1, 297: 1, 775: 1, 110: 1, 619: 1, 853: 1, 769: 1, 361: 1, 35: 1, 155: 1, 732: 1, 654: 1, 192: 1, 154: 1, 735: 1, 468: 1, 383: 1, 111: 1, 567: 1, 189: 1, 217: 1, 68: 1, 32: 1, 798: 1, 308: 1, 577: 1, 782: 1, 53: 1, 406: 1, 454: 1, 108: 1, 214: 1, 73: 1, 664: 1, 810: 1, 455: 1, 631: 1, 508: 1, 764: 1, 638: 1, 304: 1, 763: 1, 52: 1, 591: 1, 771: 1, 572: 1, 407: 1, 360: 1, 152: 1, 849: 1, 141: 1, 248: 1, 765: 1, 705: 1, 124: 1, 277: 1, 69: 1, 131: 1, 249: 1, 796: 1, 598: 1, 794: 1, 80: 1, 663: 1, 243: 1, 553: 1, 251: 1, 693: 1, 583: 1, 117: 1, 590: 1, 674: 1, 236: 1, 384: 1, 30: 1, 622: 1, 691: 1, 435: 1, 171: 1, 309: 1, 41: 1, 310: 1, 123: 1, 704: 1, 702: 1, 352: 1, 448: 1, 495: 1, 166: 1, 420: 1, 856: 1, 640: 1, 685: 1, 831: 1, 252: 1, 242: 1, 431: 1, 228: 1, 169: 1, 783: 1, 356: 1, 802: 1, 387: 1, 324: 1, 19: 1, 800: 1, 225: 1, 565: 1, 138: 1, 347: 1, 473: 1, 100: 1, 183: 1, 97: 1, 672: 1, 784: 1, 445: 1, 210: 1, 268: 1, 658: 1, 662: 1, 20: 1, 134: 1, 687: 1, 513: 1, 660: 1, 13: 1, 720: 1, 584: 1, 346: 1, 55: 1, 99: 1, 675: 1, 876: 1, 209: 1, 410: 1, 690: 1, 701: 1, 241: 1, 238: 1, 723: 1, 337: 1, 686: 1, 98: 1, 278: 1, 851: 1, 434: 1, 515: 1, 354: 1, 699: 1, 627: 1, 40: 1, 478: 1, 179: 1, 861: 1, 544: 1, 484: 1, 499: 1, 366: 1, 257: 1, 441: 1, 617: 1, 119: 1, 786: 1, 351: 1, 329: 1, 749: 1, 582: 1, 334: 1, 142: 1, 483: 1, 106: 1, 747: 1, 486: 1, 539: 1, 524: 1, 77: 1, 596: 1, 533: 1, 15: 1, 698: 1, 776: 1, 695: 1, 49: 1, 121: 1, 666: 1, 194: 1, 510: 1, 737: 1, 82: 1, 89: 1, 178: 1, 797: 1, 599: 1, 85: 1, 774: 1, 230: 1, 444: 1, 348: 1, 51: 1, 282: 1, 181: 1, 589: 1, 75: 1, 491: 1, 867: 1, 507: 1, 147: 1, 751: 1, 177: 1, 2: 1, 418: 1, 458: 1, 350: 1, 313: 1, 22: 1, 593: 1, 494: 1, 368: 1, 814: 1, 843: 1, 462: 1, 713: 1, 621: 1, 182: 1, 811: 1, 359: 1, 26: 1, 234: 1, 864: 1, 825: 1, 714: 1, 205: 1, 647: 1, 114: 1, 787: 1, 31: 1, 331: 1, 270: 1, 46: 1, 694: 1, 411: 1, 385: 1, 801: 1, 312: 1, 212: 1, 377: 1, 879: 1, 380: 1, 447: 1, 317: 1, 91: 1, 286: 1, 463: 1, 363: 1, 379: 1, 54: 1, 289: 1, 125: 1, 396: 1, 62: 1, 174: 1, 276: 1, 4: 1, 517: 1, 504: 1, 740: 1, 669: 1, 185: 1, 522: 1, 170: 1, 503: 1, 294: 1, 729: 1, 197: 1, 190: 1, 87: 1, 832: 1, 224: 1, 710: 1, 400: 1, 678: 1, 186: 1, 878: 1, 233: 1, 875: 1, 266: 1, 532: 1, 812: 1, 394: 1, 573: 1, 614: 1, 872: 1, 651: 1, 518: 1, 804: 1, 648: 1, 727: 1, 659: 1, 70: 1, 545: 1, 256: 1, 649: 1, 215: 1, 781: 1, 822: 1, 778: 1, 827: 1, 476: 1, 244: 1, 349: 1, 180: 1, 485: 1, 399: 1, 60: 1, 728: 1, 247: 1, 367: 1, 742: 1, 372: 1, 558: 1, 322: 1, 637: 1, 700: 1, 338: 1, 818: 1, 36: 1, 393: 1, 543: 1, 526: 1, 626: 1, 807: 1, 612: 1, 1: 1, 537: 1, 516: 1, 595: 1, 461: 1, 412: 1, 355: 1, 164: 1, 760: 1, 5: 1, 136: 1, 489: 1, 736: 1, 427: 1, 681: 1, 369: 1, 645: 1, 290: 1, 14: 1, 835: 1, 603: 1, 43: 1, 198: 1, 128: 1, 570: 1, 568: 1, 391: 1, 437: 1, 120: 1, 335: 1, 490: 1, 574: 1, 523: 1, 305: 1, 283: 1, 90: 1, 306: 1, 708: 1, 344: 1, 759: 1, 438: 1, 267: 1, 163: 1, 95: 1, 586: 1, 531: 1, 501: 1, 57: 1, 319: 1, 25: 1, 520: 1, 535: 1, 633: 1, 58: 1, 470: 1, 307: 1, 83: 1, 221: 1, 724: 1, 646: 1, 819: 1, 390: 1, 493: 1, 115: 1, 113: 1, 692: 1, 187: 1, 116: 1, 575: 1, 207: 1, 213: 1, 157: 1, 86: 1, 768: 1, 706: 1, 301: 1, 284: 1, 156: 1, 293: 1, 873: 1, 716: 1, 551: 1, 61: 1, 854: 1, 772: 1, 496: 1, 439: 1, 414: 1, 362: 1, 850: 1, 27: 1, 755: 1, 146: 1, 594: 1, 353: 1, 718: 1, 497: 1, 172: 1, 795: 1, 358: 1, 566: 1, 78: 1, 842: 1, 45: 1, 696: 1, 132: 1, 618: 1, 813: 1, 592: 1, 320: 1, 580: 1, 425: 1, 381: 1, 373: 1, 7: 1, 127: 1, 870: 1, 42: 1, 279: 1, 766: 1, 820: 1, 588: 1, 632: 1, 480: 1, 777: 1, 466: 1, 585: 1, 6: 1, 184: 1, 752: 1, 88: 1, 23: 1, 208: 1, 821: 1, 676: 1, 296: 1, 18: 1, 785: 1, 122: 1, 509: 1, 254: 1, 392: 1, 382: 1, 219: 1, 745: 1, 709: 1, 370: 1, 550: 1, 465: 1, 330: 1, 321: 1, 607: 1, 711: 1, 398: 1, 652: 1, 665: 1, 534: 1, 10: 1, 253: 1, 450: 1, 500: 1, 364: 1, 422: 1, 748: 1, 126: 1, 421: 1, 643: 1, 413: 1, 218: 1, 521: 1, 815: 1, 303: 1, 426: 1, 620: 1, 857: 1, 734: 1, 547: 1, 860: 1, 151: 1, 600: 1, 790: 1, 868: 1, 859: 1, 527: 1, 432: 1, 404: 1, 657: 1, 92: 1, 830: 1, 557: 1, 342: 1, 264: 1, 193: 1, 37: 1, 578: 1, 452: 1, 834: 1, 605: 1, 200: 1, 841: 1, 9: 1, 59: 1, 443: 1, 634: 1, 847: 1, 56: 1, 285: 1, 17: 1, 287: 1, 255: 1, 104: 1, 791: 1, 226: 1, 263: 1, 456: 1, 371: 1, 81: 1, 472: 1, 530: 1, 389: 1, 333: 1, 409: 1, 628: 1, 862: 1, 112: 1, 0: 1, 639: 1, 511: 1, 47: 1, 65: 1, 332: 1, 865: 1, 430: 1, 561: 1, 239: 1, 442: 1, 677: 1, 757: 1, 613: 1, 74: 1, 79: 1, 756: 1, 129: 1, 482: 1, 788: 1, 222: 1, 719: 1, 376: 1, 261: 1, 725: 1, 72: 1, 220: 1, 168: 1, 424: 1, 33: 1, 94: 1, 274: 1, 148: 1, 275: 1, 602: 1, 630: 1, 529: 1, 459: 1, 817: 1, 866: 1, 165: 1, 328: 1, 29: 1, 302: 1, 341: 1, 316: 1, 315: 1, 150: 1, 601: 1, 423: 1, 203: 1, 446: 1, 625: 1, 488: 1, 374: 1, 773: 1, 479: 1, 680: 1, 176: 1, 39: 1, 408: 1, 650: 1, 388: 1, 642: 1, 789: 1, 837: 1, 525: 1, 809: 1, 281: 1, 191: 1, 644: 1, 661: 1, 259: 1, 298: 1, 806: 1, 871: 1, 314: 1, 250: 1, 173: 1, 656: 1, 63: 1, 405: 1, 188: 1, 869: 1, 739: 1, 828: 1, 874: 1, 345: 1, 133: 1, 615: 1, 326: 1, 610: 1, 668: 1, 750: 1, 340: 1, 758: 1, 779: 1, 743: 1, 559: 1, 762: 1, 715: 1}\n",
      "Train majority class:  451\n",
      "testing train\n",
      "705\n",
      "176\n",
      "size of fold\n",
      "train:  705\n",
      "test:  176\n",
      "ranked list:  2592\n",
      "Train class count:  {5: 83, 6: 593, 4: 28, 7: 1}\n",
      "Train majority class:  6\n",
      "Train majority class accuracy:  0.8411347517730496\n",
      "N:  10\n",
      "solutions:  10\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "solution goodness:  0.8629130966952264\n",
      "best solution:  {'selected_features_indices': array([ 165, 2546, 1233, ..., 1869, 1058,  950]), 'unselected_features_indices': array([], dtype=int64), 'training_accuracy': 0.8629130966952264, 'testing_accuracy': 0.5284090909090909}\n",
      "average training accuracy:  0.8630912135525002\n",
      "average testing accuracy:  0.5289419619928094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8630912135525002, 0.5289419619928094)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train with the ckplus_dataset with the svm classifier\n",
    "\n",
    "#create a support vector machine classifier using sklearn\n",
    "svm_classifier = svm.SVC()\n",
    "\n",
    "train_test(ckplus_dict, svm_classifier)\n",
    "\n",
    "\n",
    "# train with the kaggle dataset with the svm classifier\n",
    "\n",
    "#create a support vector machine classifier using sklearn\n",
    "# svm_classifier = svm.SVC()\n",
    "\n",
    "# train_test(kaggle_dict, svm_classifier)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Computer_Vision-ERhKS5AB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
